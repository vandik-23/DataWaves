{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f54965d-49a4-452d-8bfe-2926b03be24a",
   "metadata": {},
   "source": [
    "# Wind field preparation pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75f104-9fe8-4473-a3e4-51601279681b",
   "metadata": {},
   "source": [
    "## 1. Import & install neccessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb3a3b8-8874-4244-8208-4b7b3b205bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de3334-4363-4275-909f-97cad76ebd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e7aa4e-f57c-4b06-a89d-cd60dc81f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meteoswiss Data Download\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine, text\n",
    "from dateutil import tz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdaa0a3c-5f92-4cf3-b8f8-09c44e2fb017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WindNinja CLI\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil import tz\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea161f0c-00ad-43c9-80df-9517396ee42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcPy Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639b89f1-1acb-40ca-b461-457d3994c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIKE Dataprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988da15-611a-4ed2-a451-461be90abf5b",
   "metadata": {},
   "source": [
    "## 2. Download and prepare data using MeteoSwiss API to a local MYSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a82d7e0-b822-4952-876f-0466fd4aa795",
   "metadata": {},
   "source": [
    "API documentation source: https://opendatadocs.meteoswiss.ch/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9676a5-d630-4953-b17e-ba3c4c1dd7f1",
   "metadata": {},
   "source": [
    "#### 2.1 Set variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a9e706-549e-4cbe-9136-2257dfa39899",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASS')}@\"\n",
    "    f\"{os.getenv('DB_HOST')}:{int(os.getenv('DB_PORT', 3306))}/{os.getenv('DB_NAME')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86cdcad6-c01a-4f95-ba73-dbbb1d6e0e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection successful!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"✅ Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Connection failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49138d27-c725-4494-a14e-b592638522f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: limit by local time window (e.g., this year to today); leave as None to load all \"recent\"\n",
    "LOCAL_START = \"2025-11-27 00:00\"   # Europe/Zurich (or None)\n",
    "LOCAL_END   = None #\"2025-02-01 00:00\"  #None                 # if None, no upper bound; else e.g. \"2025-10-28 23:59\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b808bf9-7ed8-4253-b8e2-885a702e94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meteoswiss CONSTANTS \n",
    "BASE = \"https://data.geo.admin.ch/ch.meteoschweiz.ogd-smn\"\n",
    "PAR_TEMP = \"tre200s0\"   # °C\n",
    "PAR_WS   = \"fve010z0\"   # m/s (requested)\n",
    "PAR_WD   = \"dkl010z0\"   # degrees (from-direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef2b830-ae89-401e-9328-e0a881c57f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\n",
    "    \"User-Agent\": \"wind-pipeline/1.0 (+your.email@example.com)\",\n",
    "    \"Accept\": \"text/csv,*/*;q=0.1\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd70c2d-075b-423f-865c-c74432bb276d",
   "metadata": {},
   "source": [
    "#### 2.2. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be262617-4181-447d-8ced-1dc389a6a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stations(engine):\n",
    "    q = \"SELECT station_id, COALESCE(local_tz,'Europe/Zurich') AS local_tz FROM stations\"\n",
    "    return pd.read_sql(q, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb56abd-7e64-4e0c-a819-af3916fcc8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_recent_csv(station_id: str) -> pd.DataFrame:\n",
    "    st = station_id.lower()\n",
    "    # correct path includes station subdirectory:\n",
    "    url = f\"{BASE}/{st}/ogd-smn_{st}_t_recent.csv\"\n",
    "    r = SESSION.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return pd.read_csv(io.BytesIO(r.content), sep=\";\", encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1c63d6-00ae-4e87-9489-15eac659c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_time_col(df):\n",
    "    # Common header names seen in OGD files\n",
    "    candidates = (\"reference_timestamp\")\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c in low:\n",
    "            return low[c]\n",
    "    # fallback to first column\n",
    "    return df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb5a410-e97a-4ca3-97d7-c4089f94af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rows(df_raw, station_tz, local_start=None, local_end=None):\n",
    "    tcol = find_time_col(df_raw)\n",
    "    ts_utc = pd.to_datetime(df_raw[tcol], errors=\"coerce\", dayfirst=True, utc=True)\n",
    "\n",
    "    tz_loc = tz.gettz(station_tz or \"Europe/Zurich\")\n",
    "    ts_local = ts_utc.dt.tz_convert(tz_loc).dt.tz_localize(None)\n",
    "\n",
    "    df = df_raw.assign(tz_utc=ts_utc.dt.tz_convert(\"UTC\").dt.tz_localize(None),\n",
    "                       tz_local=ts_local)\n",
    "\n",
    "    if local_start is not None:\n",
    "        s_local = pd.Timestamp(local_start, tz=tz_loc).tz_convert(tz_loc).tz_localize(None)\n",
    "        df = df[df[\"tz_local\"] >= s_local]\n",
    "    if local_end is not None:\n",
    "        e_local = pd.Timestamp(local_end, tz=tz_loc).tz_convert(tz_loc).tz_localize(None)\n",
    "        df = df[df[\"tz_local\"] <= e_local]\n",
    "\n",
    "    temp_c        = pd.to_numeric(df.get(PAR_TEMP), errors=\"coerce\")\n",
    "    wind_speed_ms = pd.to_numeric(df.get(PAR_WS),   errors=\"coerce\")\n",
    "    wind_dir_deg  = pd.to_numeric(df.get(PAR_WD),   errors=\"coerce\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"tz_utc\":   df[\"tz_utc\"].dt.floor(\"10min\"),\n",
    "        \"tz_local\": df[\"tz_local\"].dt.floor(\"10min\"),\n",
    "        \"data_type\": \"observation\",\n",
    "        \"temp_c\":   temp_c.round(2),\n",
    "        \"temp_unit\": \"C\",\n",
    "        \"wind_speed_ms\": wind_speed_ms.round(3),\n",
    "        \"wind_speed_temp_unit\": \"m/s\",\n",
    "        \"wind_dir_deg\":  wind_dir_deg.round(1),\n",
    "        \"source_info\": \"meteoswiss\",\n",
    "    }).dropna(subset=[\"tz_utc\",\"tz_local\",\"wind_speed_ms\",\"wind_dir_deg\"])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d336cd68-6bc1-4d63-b904-0432fc07b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_obs(engine, station_id, frame):\n",
    "    if frame.empty:\n",
    "        return 0\n",
    "    frame = frame.copy()\n",
    "    frame[\"station_id\"] = station_id\n",
    "\n",
    "    # — If your UNIQUE KEY is (station_id, tz_utc, data_type), this ON DUPLICATE is safe and idempotent.\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO meteo_obs\n",
    "      (station_id, tz_utc, tz_local, data_type,\n",
    "       temp_c, temp_unit, wind_speed_ms, wind_speed_temp_unit, wind_dir_deg,\n",
    "       source_info)\n",
    "    VALUES\n",
    "      (:station_id, :tz_utc, :tz_local, :data_type,\n",
    "       :temp_c, :temp_unit, :wind_speed_ms, :wind_speed_temp_unit, :wind_dir_deg,\n",
    "       :source_info)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "       temp_c=VALUES(temp_c),\n",
    "       temp_unit=VALUES(temp_unit),\n",
    "       wind_speed_ms=VALUES(wind_speed_ms),\n",
    "       wind_speed_temp_unit=VALUES(wind_speed_temp_unit),\n",
    "       wind_dir_deg=VALUES(wind_dir_deg),\n",
    "       source_info=VALUES(source_info),\n",
    "       created_sys_time=CURRENT_TIMESTAMP;\n",
    "    \"\"\"\n",
    "    cols = [\"station_id\",\"tz_utc\",\"tz_local\",\"data_type\",\n",
    "            \"temp_c\",\"temp_unit\",\"wind_speed_ms\",\"wind_speed_temp_unit\",\"wind_dir_deg\",\n",
    "            \"source_info\"]\n",
    "    batch = frame[cols].to_dict(orient=\"records\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for i in range(0, len(batch), 800):\n",
    "            conn.execute(text(sql), batch[i:i+800])\n",
    "    return len(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76b89e25-ac22-4619-b8e1-6591d725cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FRU] upserted 726 recent rows.\n",
      "[INT] upserted 726 recent rows.\n",
      "[THU] upserted 726 recent rows.\n",
      "Done. Total rows upserted: 2178\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN ====\n",
    "\n",
    "stations = fetch_stations(engine)\n",
    "total = 0\n",
    "for _, row in stations.iterrows():\n",
    "    st = row[\"station_id\"]\n",
    "    tz_name = row[\"local_tz\"] or \"Europe/Zurich\"\n",
    "    try:\n",
    "        raw = fetch_recent_csv(st)\n",
    "        prepared = prepare_rows(raw, tz_name, local_start=LOCAL_START, local_end=LOCAL_END)\n",
    "        n = upsert_obs(engine, st, prepared)\n",
    "        print(f\"[{st}] upserted {n} recent rows.\")\n",
    "        total += n\n",
    "    except Exception as e:\n",
    "        print(f\"[{st}] ERROR: {e}\")\n",
    "\n",
    "print(f\"Done. Total rows upserted: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d39d2-1708-46c1-8d25-f3b8949102c7",
   "metadata": {},
   "source": [
    "#### 2.3 Run initial data load to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a7c2b3d-e7e6-4366-b4b2-e4ca18d80269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FRU] upserted 38742 recent rows.\n",
      "[INT] upserted 38742 recent rows.\n",
      "[THU] upserted 38742 recent rows.\n",
      "Done. Total rows upserted: 116226\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN ====\n",
    "\n",
    "stations = fetch_stations(engine)\n",
    "total = 0\n",
    "for _, row in stations.iterrows():\n",
    "    st = row[\"station_id\"]\n",
    "    tz_name = row[\"local_tz\"] or \"Europe/Zurich\"\n",
    "    try:\n",
    "        raw = fetch_recent_csv(st)\n",
    "        prepared = prepare_rows(raw, tz_name, local_start=LOCAL_START, local_end=LOCAL_END)\n",
    "        n = upsert_obs(engine, st, prepared)\n",
    "        print(f\"[{st}] upserted {n} recent rows.\")\n",
    "        total += n\n",
    "    except Exception as e:\n",
    "        print(f\"[{st}] ERROR: {e}\")\n",
    "\n",
    "print(f\"Done. Total rows upserted: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b5078-69fe-4272-b4d7-6a9387ab14e8",
   "metadata": {},
   "source": [
    "#### 2.4. Download and prepare 48 hours weather data using MeteoSwiss API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb87272f-cfac-4f1b-9848-a535575a75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute timestamps from last 48 h back from now\n",
    "\n",
    "def last_48h_window_utc(now_utc=None):\n",
    "    \"\"\"Return (start_utc, end_utc) as naive UTC pandas Timestamps aligned to 10-min grid.\"\"\"\n",
    "    if now_utc is None:\n",
    "        now_utc = pd.Timestamp.utcnow()\n",
    "    end_utc = now_utc.floor(\"10min\")\n",
    "    start_utc = end_utc - pd.Timedelta(hours=48)\n",
    "    # Make them naive (match your tz_utc DATETIME column)\n",
    "    return start_utc.tz_localize(None), end_utc.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17a02d43-dafe-41ab-977d-3405e8a6c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the computed timestamps\n",
    "\n",
    "def filter_last_48h(frame):\n",
    "    if frame.empty:\n",
    "        return frame\n",
    "    start_utc, end_utc = last_48h_window_utc()\n",
    "    # Ensure tz_utc is datetime64[ns] naive\n",
    "    f = frame.copy()\n",
    "    f[\"tz_utc\"] = pd.to_datetime(f[\"tz_utc\"])\n",
    "    return f[(f[\"tz_utc\"] >= start_utc) & (f[\"tz_utc\"] <= end_utc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d022ca7-62bd-4fa0-96ff-0a9774f6589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_existing_in_window(engine, station_id, frame_48h):\n",
    "    if frame_48h.empty:\n",
    "        return frame_48h\n",
    "    start_utc = frame_48h[\"tz_utc\"].min()\n",
    "    end_utc   = frame_48h[\"tz_utc\"].max()\n",
    "    sql = \"\"\"\n",
    "      SELECT tz_utc\n",
    "      FROM meteo_obs\n",
    "      WHERE station_id = :station_id\n",
    "        AND tz_utc BETWEEN :start_utc AND :end_utc\n",
    "    \"\"\"\n",
    "    existing = pd.read_sql(\n",
    "        text(sql),\n",
    "        engine,  # <- pass engine, not a transactional connection\n",
    "        params={\"station_id\": station_id, \"start_utc\": start_utc, \"end_utc\": end_utc}\n",
    "    )\n",
    "    if existing.empty:\n",
    "        return frame_48h\n",
    "    existing_set = set(pd.to_datetime(existing[\"tz_utc\"]))\n",
    "    return frame_48h[~frame_48h[\"tz_utc\"].isin(existing_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b152f86c-a9ea-4869-87d0-5aa0e40eeaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsert new data in the DB\n",
    "\n",
    "def upsert_obs_last48h(engine, station_id, frame):\n",
    "    f48 = filter_last_48h(frame)\n",
    "    if f48.empty:\n",
    "        return 0\n",
    "    f_new = drop_existing_in_window(engine, station_id, f48)\n",
    "    if f_new.empty:\n",
    "        return 0\n",
    "\n",
    "    f_new = f_new.copy()\n",
    "    f_new[\"station_id\"] = station_id\n",
    "\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO meteo_obs\n",
    "      (station_id, tz_utc, tz_local, data_type,\n",
    "       temp_c, temp_unit, wind_speed_ms, wind_speed_temp_unit, wind_dir_deg, source_info)\n",
    "    VALUES\n",
    "      (:station_id, :tz_utc, :tz_local, :data_type,\n",
    "       :temp_c, :temp_unit, :wind_speed_ms, :wind_speed_temp_unit, :wind_dir_deg, :source_info)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "       temp_c=VALUES(temp_c),\n",
    "       temp_unit=VALUES(temp_unit),\n",
    "       wind_speed_ms=VALUES(wind_speed_ms),\n",
    "       wind_speed_temp_unit=VALUES(wind_speed_temp_unit),\n",
    "       wind_dir_deg=VALUES(wind_dir_deg),\n",
    "       source_info=VALUES(source_info);\n",
    "    \"\"\"\n",
    "    rows = f_new[[\"station_id\",\"tz_utc\",\"tz_local\",\"data_type\",\n",
    "                  \"temp_c\",\"temp_unit\",\"wind_speed_ms\",\"wind_speed_temp_unit\",\n",
    "                  \"wind_dir_deg\",\"source_info\"]].to_dict(orient=\"records\")\n",
    "\n",
    "    # independent transaction; auto-rollback on exception\n",
    "    from sqlalchemy import text\n",
    "    with engine.begin() as conn:\n",
    "        for i in range(0, len(rows), 800):\n",
    "            conn.execute(text(sql), rows[i:i+800])\n",
    "    return len(f_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "907993a0-bc2d-4a5b-8497-0220552f7ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FRU] upserted 0 rows (last 48h).\n",
      "[INT] upserted 0 rows (last 48h).\n",
      "[THU] upserted 0 rows (last 48h).\n",
      "Done. Total rows upserted: 0\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN DAILYUPDATE (48h only) ====\n",
    "stations = fetch_stations(engine)\n",
    "total = 0\n",
    "for _, row in stations.iterrows():\n",
    "    st = row[\"station_id\"]\n",
    "    tz_name = row.get(\"local_tz\") or \"Europe/Zurich\"\n",
    "    try:\n",
    "        raw = fetch_recent_csv(st)\n",
    "        prepared = prepare_rows(raw, tz_name, local_start=None, local_end=None)\n",
    "        n = upsert_obs_last48h(engine, st, prepared)\n",
    "        print(f\"[{st}] upserted {n} rows (last 48h).\")\n",
    "        total += n\n",
    "    except Exception as e:\n",
    "        print(f\"[{st}] ERROR: {e}\")\n",
    "        # Optional: drop tainted connections from pool after a DB error\n",
    "        engine.dispose()\n",
    "print(f\"Done. Total rows upserted: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee28ff-5da1-4bf1-bbd2-85956757430b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef5b67-41f9-4ce2-a5e7-1aa544fc349e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14dbf4b-9099-4d68-9395-f12924105ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ffbd4-42ab-4786-829f-4de62585184d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f30f6-d28e-4be5-bcbe-960456d8dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d63e6-5d4a-48b6-86f2-615ae8a65203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d8c39-c361-4b44-be63-3d34180b6481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Webcamscraper)",
   "language": "python",
   "name": "webcamscraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
