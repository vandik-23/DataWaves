{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef44b6ee-b30b-4809-ad0b-a47410506127",
   "metadata": {},
   "source": [
    "# Image Labeling & Model Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc9c2c-2d77-4f5d-a8cc-5a5763179e08",
   "metadata": {},
   "source": [
    "## 1. Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8d3a3d-e0d1-4fb6-b276-356ac16aaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8d6134-91fa-496c-aa04-b3704f3f33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718ef1da-295a-4c15-874f-5aeab18fb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2096e6-0dbe-486d-a04e-b5ec3b1abdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b046e1b8-2a40-4d4a-aaa9-b4c471a56953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf86f6eb-ac7b-4c10-bcb0-7b19c8a60066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47159055-f2ac-45a6-936f-ab136687d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "from ultralytics.data import utils as data_utils\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9a91df-ae56-49c9-ae32-7fea201abdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4c3159-a524-404f-8f31-b7b33e452fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab7903-0616-4203-b290-6369b94a4471",
   "metadata": {},
   "source": [
    "## 2. Define Paths to Folders & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cbb0b4-6bbc-40d8-8f25-27b2686ae917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source images located in: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up one level to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Set path for the source folder (you can adjust as needed)\n",
    "source_folder = os.path.join(parent_dir, \"idx_images\")\n",
    "labeling_folder = os.path.join(parent_dir, \"img_labeling\")\n",
    "\n",
    "csv_out_path = os.path.join(source_folder, \"image_metadata_weather.csv\")\n",
    "csv_train = os.path.join(labeling_folder, \"train_for_training.csv\")\n",
    "csv_test = os.path.join(labeling_folder, \"test_for_training.csv\")\n",
    "csv_val = os.path.join(labeling_folder, \"val_for_training.csv\")\n",
    "\n",
    "print(f\"Source images located in: {source_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630c9e6d-73c1-4eaa-98d9-1a8a90d52bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted([f for f in os.listdir(source_folder) if f.endswith('.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f391b779-461a-473d-978b-a28d083bd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27592 images found\n"
     ]
    }
   ],
   "source": [
    "print(len(image_files), \"images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a249e63e-0851-4e09-a00a-a1d0dc84ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO model (load once)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f3473-41de-4c04-8240-1389b2d1cab9",
   "metadata": {},
   "source": [
    "## 3. Finetuning YOLO Model using stratified Train, Test, Val set and created labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21fe4fb-2a5a-4607-a57c-4665e36e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset root where YOLO dataset will be automatically created\n",
    "dataset_root = os.path.join(parent_dir, \"waves_yolo_dataset_1000_small\")\n",
    "os.makedirs(dataset_root, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d0c694-0396-4629-a0e2-69f570911382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lists of image names\n",
    "# -------------------------------------------------------------\n",
    "def load_image_list(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"new_image_name\" in df.columns:\n",
    "        col = \"new_image_name\"\n",
    "    elif \"image_name\" in df.columns:\n",
    "        col = \"image_name\"\n",
    "    else:\n",
    "        raise ValueError(f\"No image name column in {csv_path}\")\n",
    "    return df[col].dropna().astype(str).tolist()\n",
    "\n",
    "# Load ALL images from CSVs\n",
    "train_imgs_full = load_image_list(csv_train)\n",
    "val_imgs_full   = load_image_list(csv_val)\n",
    "test_imgs_full  = load_image_list(csv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84336701-1cb7-44a5-a0bf-d70149e3d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset: train=1000, val=200, test=200\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Subsample: 500 train, 200 val, 200 test\n",
    "# (shuffled so you don't just get the first rows)\n",
    "# -------------------------------------------------------------\n",
    "random.seed(42)  # for reproducibility\n",
    "\n",
    "train_imgs = random.sample(train_imgs_full, min(1000, len(train_imgs_full)))\n",
    "val_imgs   = random.sample(val_imgs_full,  min(200, len(val_imgs_full)))\n",
    "test_imgs  = random.sample(test_imgs_full, min(200, len(test_imgs_full)))\n",
    "\n",
    "print(f\"Using subset: train={len(train_imgs)}, val={len(val_imgs)}, test={len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3afe552c-a9a9-44ea-9d21-f46d6a17710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote split files:\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\train.txt\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\val.txt\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# Write YOLO split txt files with ABSOLUTE PATHS\n",
    "# -------------------------------------------------------------\n",
    "def write_split_file(img_list, out_path):\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for name in img_list:\n",
    "            full_path = os.path.abspath(os.path.join(source_folder, name))\n",
    "            f.write(full_path + \"\\n\")\n",
    "\n",
    "train_txt = os.path.join(dataset_root, \"train.txt\")\n",
    "val_txt   = os.path.join(dataset_root, \"val.txt\")\n",
    "test_txt  = os.path.join(dataset_root, \"test.txt\")\n",
    "\n",
    "write_split_file(train_imgs, train_txt)\n",
    "write_split_file(val_imgs, val_txt)\n",
    "write_split_file(test_imgs, test_txt)\n",
    "\n",
    "print(\"Wrote split files:\")\n",
    "print(train_txt)\n",
    "print(val_txt)\n",
    "print(test_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6cf582-3197-45fe-8414-29c5f197c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data.yaml at: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\03_waves.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create YOLO data.yaml\n",
    "# IMPORTANT: 'path' tells YOLO where labels live.\n",
    "# -------------------------------------------------------------\n",
    "# Normalize Windows paths before inserting into f-string\n",
    "train_txt_norm = train_txt.replace(\"\\\\\", \"/\")\n",
    "val_txt_norm   = val_txt.replace(\"\\\\\", \"/\")\n",
    "test_txt_norm  = test_txt.replace(\"\\\\\", \"/\")\n",
    "parent_dir_norm = parent_dir.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Create YOLO data.yaml\n",
    "data_yaml_path = os.path.join(dataset_root, \"03_waves.yaml\")\n",
    "\n",
    "yaml_text = f\"\"\"\n",
    "# Dataset config without copying images\n",
    "\n",
    "train: {train_txt_norm}\n",
    "val: {val_txt_norm}\n",
    "test: {test_txt_norm}\n",
    "\n",
    "names:\n",
    "  0: wave\n",
    "nc: 1\n",
    "\"\"\"\n",
    "\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "print(\"Created data.yaml at:\", data_yaml_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d969d-af64-4f67-aba9-911b3fbdc2df",
   "metadata": {},
   "source": [
    "##### Load model and checking if model finds labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1cb12c-e561-4c42-bb6b-675061544355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train source: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\train.txt\n",
      "Val source:   C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\val.txt\n",
      "Test source:  C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_small\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model first try nano than small or medium\n",
    "base_model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "info = data_utils.check_det_dataset(data_yaml_path)\n",
    "print(\"Train source:\", info[\"train\"])\n",
    "print(\"Val source:  \", info[\"val\"])\n",
    "print(\"Test source: \", info[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d2c49e1-55fe-4a15-9ac5-0d5e4c59aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing train labels: 1000\n",
      "Missing val labels:   200\n",
      "Missing test labels:  200\n",
      "Example missing label: ['img_14237.txt', 'img_15383.txt', 'img_04648.txt', 'img_16453.txt', 'img_06242.txt']\n"
     ]
    }
   ],
   "source": [
    "def count_missing_labels(txt_file, label_folder):\n",
    "    missing = []\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:\n",
    "            img_path = line.strip()\n",
    "            img_name = Path(img_path).name\n",
    "            label_name = img_name.replace(\".png\", \".txt\")\n",
    "            label_path = Path(label_folder) / label_name\n",
    "            if not label_path.exists():\n",
    "                missing.append(label_name)\n",
    "    return missing\n",
    "\n",
    "labels_folder = r\"C:/Users/A/Documents/XX_GitHub_Repo/data-waves/labels\"\n",
    "\n",
    "missing_train = count_missing_labels(info[\"train\"], labels_folder)\n",
    "missing_val   = count_missing_labels(info[\"val\"], labels_folder)\n",
    "missing_test  = count_missing_labels(info[\"test\"], labels_folder)\n",
    "\n",
    "print(\"Missing train labels:\", len(missing_train))\n",
    "print(\"Missing val labels:  \", len(missing_val))\n",
    "print(\"Missing test labels: \", len(missing_test))\n",
    "\n",
    "if missing_train:\n",
    "    print(\"Example missing label:\", missing_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c884d-0006-412c-b516-0e282cea4496",
   "metadata": {},
   "source": [
    "##### Run finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0008cb-a5dc-4d34-b965-4d395e164bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA is available. Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Device selection (GPU if available, else CPU)\n",
    "# ------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = 0  # GPU index for ultralytics (0 = first GPU)\n",
    "    print(\"✅ CUDA is available. Training on GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"⚠️ CUDA not available. Training on CPU (slower).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08344f72-3e75-432d-811c-89055e769b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.231 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.230  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\haas\\data-waves\\waves_yolo_dataset_1000_small\\03_waves.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=(512, 2048), int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=03_waves_yolov8s-1000_150e, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING updating to 'imgsz=2048'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 360.814.2 MB/s, size: 2393.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\haas\\data-waves\\idx_images.cache... 1000 images, 62 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 64.0Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 205.4123.9 MB/s, size: 2424.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\haas\\data-waves\\idx_images... 200 images, 10 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 177.8it/s 1.1s.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\haas\\data-waves\\idx_images.cache\n",
      "Plotting labels to C:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 2048 train, 2048 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/150       7.8G      4.186      11.37     0.9136          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.4it/s 3:460.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.2s\n",
      "                   all        200     127491     0.0111    0.00421    0.00559     0.0013\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/150      7.37G      4.111      3.273     0.8675        438       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:300.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0162     0.0064    0.00825    0.00191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/150      9.66G      4.119      3.155      0.864         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.4it/s 3:050.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0114    0.00484    0.00585    0.00138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/150      9.12G      4.143      2.939     0.8736        277       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:580.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 4.9it/s 20.3s.5ss\n",
      "                   all        200     127491     0.0104    0.00435    0.00528    0.00125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/150      9.25G      4.038      2.857     0.8493         19       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.6it/s 3:380.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.4it/s 15.6s0.2s\n",
      "                   all        200     127491    0.00715    0.00281    0.00522    0.00178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/150        11G      4.126      2.916     0.8725        552       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2s/it 19:562.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.2s\n",
      "                   all        200     127491     0.0048    0.00177    0.00278   0.000688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/150      12.8G      4.148      2.913      0.876        134       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.1it/s 7:591.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.2s\n",
      "                   all        200     127491     0.0128    0.00529    0.00817     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/150      13.9G      4.087      2.879     0.8639         36       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.9it/s 8:471.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 14.0s0.1s\n",
      "                   all        200     127491      0.015    0.00673    0.00874    0.00257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/150      13.6G      4.058      2.784     0.8622        199       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.9it/s 5:471.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.1it/s 16.4s0.1s\n",
      "                   all        200     127491     0.0156    0.00596    0.00869    0.00229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/150        11G      4.055      2.806     0.8616        317       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.7it/s 6:100.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.7it/s 14.9s0.1s\n",
      "                   all        200     127491     0.0225    0.00908     0.0119    0.00297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/150      13.2G       4.04      2.794     0.8648        259       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:530.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 14.0s0.1s\n",
      "                   all        200     127491     0.0161    0.00632     0.0114     0.0032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/150       6.3G      4.049      2.742      0.861        193       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:480.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0107     0.0045    0.00656    0.00187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/150      10.6G      4.001      2.666     0.8567          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.0s/it 17:061.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.6it/s 15.1s0.2s\n",
      "                   all        200     127491     0.0117    0.00482    0.00664    0.00156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/150      6.66G      4.008       2.63     0.8545        337       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.0it/s 5:360.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.7it/s 14.9s0.1s\n",
      "                   all        200     127491     0.0161    0.00688    0.00901    0.00215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/150      9.25G      4.063      2.749     0.8664        464       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7it/s 9:421.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.7it/s 17.7s0.1s\n",
      "                   all        200     127491     0.0141    0.00578    0.00829    0.00214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/150      10.3G      3.992      2.663     0.8604        135       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.9it/s 4:140.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 2.2it/s 45.6s.7ss\n",
      "                   all        200     127491     0.0101    0.00409    0.00589    0.00144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/150        13G      3.989      2.718     0.8594        618       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.2it/s 5:130.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.9it/s 14.5s0.1s\n",
      "                   all        200     127491     0.0175    0.00707     0.0137    0.00507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/150      9.13G      3.921      2.635     0.8427         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.8it/s 3:270.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.2s\n",
      "                   all        200     127491     0.0185    0.00751     0.0109    0.00276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/150      13.8G      4.003      2.662     0.8642       1055       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.5it/s 11:081.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0143    0.00589     0.0088    0.00224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/150      9.38G      3.933      2.603     0.8514        184       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7it/s 9:580.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.1s\n",
      "                   all        200     127491     0.0218    0.00923      0.012    0.00288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/150      9.43G      3.982      2.704     0.8554        564       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:480.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.2s\n",
      "                   all        200     127491     0.0159    0.00608    0.00958    0.00224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/150      8.67G      3.968      2.584      0.857         94       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:600.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.2s\n",
      "                   all        200     127491     0.0134    0.00541    0.00731    0.00182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/150      9.31G       3.94      2.594     0.8494         46       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.5it/s 4:420.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0118     0.0048    0.00629    0.00148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/150      8.67G      3.939      2.546     0.8527        411       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.0it/s 4:120.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.9it/s 17.0s.1s\n",
      "                   all        200     127491     0.0214    0.00873      0.012    0.00281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/150      11.1G      3.935      2.502      0.848        216       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.4it/s 3:050.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0187    0.00771     0.0143    0.00381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/150      11.2G      4.003       2.63     0.8641        188       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:510.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.1s\n",
      "                   all        200     127491     0.0185    0.00748     0.0101    0.00256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/150      13.7G      3.885      2.507     0.8479        258       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.3it/s 3:100.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.9it/s 14.4s0.2s\n",
      "                   all        200     127491     0.0233    0.00993     0.0137    0.00336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/150      12.2G      3.953      2.602     0.8556         95       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.4it/s 3:050.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0183     0.0074     0.0106    0.00291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/150      9.77G      3.992      2.558     0.8675        113       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.5it/s 3:010.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.0it/s 20.1s.5ss\n",
      "                   all        200     127491     0.0116    0.00482    0.00744    0.00206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/150      13.3G      3.998      2.603     0.8664        486       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.5it/s 4:480.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.1s\n",
      "                   all        200     127491     0.0258     0.0105     0.0155    0.00426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/150      8.26G      3.935      2.566     0.8555        946       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:351.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.1it/s 16.4s0.1s\n",
      "                   all        200     127491     0.0153     0.0062     0.0101    0.00331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/150      13.8G      3.976      2.544     0.8651        564       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.9it/s 3:260.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.8it/s 14.6s0.1s\n",
      "                   all        200     127491     0.0117     0.0045    0.00884    0.00295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/150      10.1G      3.969      2.576     0.8614        394       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.5it/s 3:030.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.9it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0158    0.00646    0.00938     0.0024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/150      13.8G      3.921      2.469     0.8496        220       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.0it/s 4:110.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.9it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0243    0.00994     0.0136    0.00336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/150      13.8G      3.921      2.642     0.8538        246       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.3it/s 5:032.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.6it/s 15.2s0.2s\n",
      "                   all        200     127491     0.0179    0.00729     0.0109    0.00255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/150      9.35G      3.946      2.535     0.8545         96       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.3it/s 12:501.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.2s\n",
      "                   all        200     127491     0.0189    0.00769     0.0115    0.00309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/150      7.59G      3.934      2.567     0.8481        537       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:310.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0188    0.00759     0.0114     0.0028\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/150      13.6G      3.929      2.595     0.8483        191       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.8it/s 6:000.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.7it/s 14.9s0.1s\n",
      "                   all        200     127491     0.0171    0.00697     0.0135    0.00351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/150      11.9G      3.914      2.499     0.8458        292       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.5it/s 4:470.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.8it/s 14.6s0.2s\n",
      "                   all        200     127491     0.0096    0.00398    0.00977    0.00414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/150      10.1G      3.964      2.543      0.856         22       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.7it/s 3:340.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0113    0.00471    0.00692     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/150      8.46G      3.939      2.494     0.8565        147       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:560.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0289     0.0117     0.0162    0.00402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/150      7.28G      3.887      2.566     0.8472         29       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.8it/s 3:280.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0176    0.00711     0.0113    0.00277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/150      9.44G      3.918      2.529     0.8545          8       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.2it/s 2:420.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0178    0.00724     0.0109    0.00294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/150      8.08G      3.932      2.545     0.8601        298       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.8it/s 5:520.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.1s\n",
      "                   all        200     127491     0.0212    0.00882     0.0125    0.00317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/150      13.2G      3.916      2.515     0.8513         78       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.4it/s 11:351.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 4.9it/s 20.2s.1s\n",
      "                   all        200     127491     0.0224    0.00921      0.013     0.0032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/150      12.4G      3.901      2.446      0.847         75       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:560.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.2s0.1s\n",
      "                   all        200     127491      0.014    0.00573    0.00835    0.00214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/150      10.9G      3.934      2.444     0.8503        172       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.9it/s 2:500.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0157    0.00638     0.0103     0.0025\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/150      11.4G      3.961      2.604     0.8594        194       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:460.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.4s0.2s\n",
      "                   all        200     127491     0.0199    0.00796     0.0124     0.0029\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/150      8.68G      3.944      2.494     0.8562        431       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.5it/s 3:030.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.1s\n",
      "                   all        200     127491       0.02    0.00831     0.0118    0.00297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/150      13.5G       3.92      2.419     0.8502        171       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.0it/s 3:210.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0199    0.00827     0.0119    0.00317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/150      12.4G        3.9      2.474     0.8496         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.9it/s 3:260.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 2.5it/s 40.5s.7ss\n",
      "                   all        200     127491     0.0221    0.00884     0.0144    0.00431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/150      9.75G      3.879      2.454     0.8436         26       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.0it/s 3:200.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.5s0.1s\n",
      "                   all        200     127491     0.0242    0.00969     0.0136    0.00349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/150      9.17G      3.795      2.425     0.8312        843       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.0it/s 5:370.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.6s0.2s\n",
      "                   all        200     127491     0.0151     0.0062       0.01     0.0026\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/150      8.11G      3.843       2.46     0.8406        319       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.7it/s 4:270.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0237    0.00937     0.0169    0.00518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/150        13G      3.896      2.479     0.8457        452       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.2it/s 3:120.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.2s0.1s\n",
      "                   all        200     127491      0.022      0.009     0.0131    0.00346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/150        13G      3.908      2.469     0.8534         13       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.0it/s 8:181.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0258     0.0106     0.0155    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/150      6.64G      3.839      2.443     0.8332          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.3it/s 2:400.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.1it/s 19.5s.5s\n",
      "                   all        200     127491     0.0189    0.00758     0.0114    0.00287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/150      10.8G      3.859      2.461     0.8398        225       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:540.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0212    0.00902      0.012    0.00299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/150      9.07G      3.891      2.466     0.8535        416       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.7it/s 3:310.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.2s\n",
      "                   all        200     127491     0.0198    0.00817     0.0112    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/150        12G      3.856      2.488     0.8429        387       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.3it/s 3:520.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.1s\n",
      "                   all        200     127491     0.0315     0.0124     0.0187    0.00507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/150      6.74G      3.869      2.463     0.8381        188       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.1it/s 2:430.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0201    0.00827     0.0129    0.00326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/150      13.5G      3.856      2.442      0.843        675       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.4it/s 3:460.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.2s\n",
      "                   all        200     127491     0.0251    0.00978     0.0175    0.00558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/150      12.9G      3.844      2.418     0.8341          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.1it/s 3:140.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0215    0.00914     0.0122    0.00315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/150      7.11G      3.869      2.409       0.84        189       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:410.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.2s\n",
      "                   all        200     127491     0.0178    0.00729     0.0107    0.00286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/150      13.3G      3.855      2.414     0.8417        287       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.9it/s 3:230.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0215    0.00868     0.0132     0.0033\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/150      10.6G      3.845      2.421     0.8427        170       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.3it/s 2:390.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0211    0.00875     0.0122    0.00309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/150        11G      3.877       2.42     0.8455        351       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.5it/s 3:000.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0171    0.00709     0.0107    0.00257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/150      13.1G      3.848       2.37     0.8431        129       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.9it/s 8:541.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0201    0.00822     0.0123    0.00323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/150      7.27G      3.834       2.38     0.8423       1383       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:310.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0256     0.0102     0.0154    0.00433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/150      10.5G      3.859      2.422     0.8438        268       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.3it/s 3:550.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0208    0.00853     0.0154     0.0038\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/150      12.5G       3.84      2.451     0.8416         43       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.2it/s 7:361.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0175    0.00732     0.0107    0.00298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/150        11G       3.88      2.421     0.8432        204       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.7it/s 3:320.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0176    0.00723     0.0106    0.00277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/150      13.6G      3.827      2.382     0.8454        570       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7it/s 9:492.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.2s0.2s\n",
      "                   all        200     127491     0.0199    0.00814     0.0115    0.00286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/150      7.53G      3.852      2.372     0.8432        587       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.7it/s 6:160.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.6it/s 15.1s0.1s\n",
      "                   all        200     127491     0.0216     0.0089     0.0133    0.00418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/150      6.69G      3.925       2.41     0.8628        232       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.5it/s 3:030.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 14.0s0.2s\n",
      "                   all        200     127491      0.021     0.0086     0.0135    0.00377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/150      9.15G      3.922      2.421     0.8544        332       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7it/s 9:560.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.7it/s 15.0s0.1s\n",
      "                   all        200     127491     0.0262     0.0106     0.0182    0.00497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/150      8.57G      3.821      2.471      0.837          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2s/it 19:341.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.6it/s 15.2s0.1s\n",
      "                   all        200     127491     0.0213    0.00884     0.0125    0.00378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/150      8.66G      3.858      2.441     0.8407        298       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:470.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0191    0.00758      0.012    0.00322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/150      8.72G      3.858      2.421     0.8458          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:330.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491      0.019    0.00762      0.012    0.00301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/150        12G      3.824      2.385     0.8346        317       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.9it/s 3:260.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0184    0.00729     0.0142    0.00439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/150       8.4G       3.86      2.423     0.8409        160       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.7it/s 3:320.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.6s0.1s\n",
      "                   all        200     127491     0.0262     0.0104     0.0148    0.00387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/150      9.26G      3.876      2.448     0.8461         88       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:530.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.0it/s 19.9s.5s\n",
      "                   all        200     127491     0.0258     0.0104     0.0151    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/150      12.6G      3.853      2.414     0.8447        392       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.4it/s 3:060.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0306     0.0123     0.0172    0.00454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/150      10.2G      3.808      2.369     0.8349        264       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.8it/s 9:010.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0226      0.009     0.0138    0.00369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/150      13.1G      3.815      2.435     0.8366        169       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.9it/s 2:490.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0279     0.0111     0.0165    0.00452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/150      8.47G      3.796      2.373     0.8255          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.3it/s 2:390.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.4it/s 18.7s.2s\n",
      "                   all        200     127491     0.0186    0.00761     0.0104    0.00262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/150      8.04G      3.864      2.371     0.8463        508       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.6it/s 6:180.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.3it/s 16.0s.1s\n",
      "                   all        200     127491     0.0224    0.00939     0.0137    0.00358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/150      12.9G      3.822      2.354     0.8383        333       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.9it/s 2:500.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0207    0.00835     0.0153    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/150      8.63G       3.81      2.357     0.8362          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.5it/s 3:020.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 14.0s0.1s\n",
      "                   all        200     127491     0.0241    0.00983     0.0154    0.00431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/150      11.6G      3.816      2.332     0.8316        420       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.1s/it 17:331.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.2s\n",
      "                   all        200     127491     0.0242     0.0098     0.0141    0.00382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/150      6.87G      3.747      2.351     0.8205          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:510.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.2s\n",
      "                   all        200     127491     0.0243     0.0097     0.0155    0.00455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/150        13G      3.876      2.397     0.8451        357       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.3it/s 12:441.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0207    0.00863      0.012    0.00316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/150      8.55G      3.785      2.346      0.833        741       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.4it/s 3:470.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.6s0.1s\n",
      "                   all        200     127491     0.0224    0.00901     0.0134    0.00392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/150      13.8G      3.834      2.366     0.8343        516       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.9it/s 3:261.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.9it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0289     0.0117     0.0171    0.00484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/150      7.24G      3.817      2.394     0.8382        276       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.1it/s 2:440.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0285     0.0116     0.0193    0.00504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/150      9.21G      3.828      2.363     0.8434        744       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7it/s 10:010.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.2s\n",
      "                   all        200     127491     0.0248     0.0101     0.0158    0.00421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/150       6.6G      3.852      2.369     0.8446        160       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:310.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.6s0.1s\n",
      "                   all        200     127491     0.0227     0.0094     0.0128    0.00338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/150      10.6G      3.807      2.378     0.8391        180       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.6it/s 3:350.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0211     0.0086      0.012     0.0031\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/150      5.97G      3.792      2.334     0.8275         55       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:530.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0246    0.00994     0.0173    0.00481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/150      9.34G      3.837      2.358     0.8383         92       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:550.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0303     0.0122     0.0203    0.00686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    101/150      10.3G      3.839      2.368      0.845        217       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.0it/s 3:200.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0247    0.00997     0.0149    0.00431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    102/150      11.7G      3.791      2.331     0.8339         24       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.6it/s 4:370.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.9it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0267     0.0109     0.0168    0.00498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    103/150      11.2G      3.786      2.354     0.8328        289       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:520.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0291     0.0118     0.0197    0.00576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    104/150      6.79G      3.792      2.348     0.8314          5       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.6it/s 6:200.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0192    0.00784     0.0129    0.00387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    105/150      11.8G      3.828      2.369     0.8378        183       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2it/s 13:601.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.4s0.1s\n",
      "                   all        200     127491     0.0304     0.0123     0.0204    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    106/150      7.63G       3.81      2.422     0.8371        321       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.1it/s 4:010.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.2s\n",
      "                   all        200     127491     0.0241    0.00993     0.0152    0.00422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    107/150      8.01G      3.801      2.334     0.8325        389       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.6it/s 6:280.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.2s\n",
      "                   all        200     127491     0.0234    0.00948     0.0142    0.00446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    108/150      10.8G      3.797      2.312     0.8377        120       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.2it/s 3:111.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.1s\n",
      "                   all        200     127491     0.0263     0.0105     0.0182    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    109/150      11.4G      3.828      2.343      0.838        120       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.4it/s 2:350.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0234    0.00959     0.0167    0.00568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    110/150      9.28G      3.797      2.324     0.8397       1393       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.8it/s 9:120.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.1s\n",
      "                   all        200     127491     0.0257     0.0106     0.0144    0.00394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    111/150      6.88G      3.823      2.346     0.8443        425       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:400.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0236     0.0095     0.0168    0.00498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    112/150      13.2G      3.787      2.336      0.832        118       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7s/it 28:431.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 4.4it/s 23.0s.2ss\n",
      "                   all        200     127491     0.0209    0.00849     0.0121    0.00326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    113/150      11.3G       3.78      2.337     0.8328         56       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:570.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491      0.024    0.00973     0.0134    0.00354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    114/150      10.2G      3.865      2.347     0.8486         19       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.3it/s 3:100.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0227    0.00932     0.0164    0.00545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    115/150      8.84G      3.813      2.316     0.8413        314       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.4it/s 4:530.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.1s\n",
      "                   all        200     127491     0.0217    0.00872      0.013    0.00342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    116/150      8.64G      3.831      2.342     0.8441         21       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.2it/s 3:550.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0233    0.00958     0.0166    0.00495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    117/150      13.9G      3.762      2.348     0.8293       1082       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.1s/it 17:502.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.0s0.1s\n",
      "                   all        200     127491     0.0252     0.0104     0.0143    0.00386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    118/150      10.5G      3.796      2.324     0.8323        430       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:530.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0226    0.00922     0.0129    0.00319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    119/150      6.66G      3.779      2.326     0.8373        144       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.9it/s 2:490.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.6s0.2s\n",
      "                   all        200     127491     0.0215    0.00859     0.0132    0.00383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    120/150      7.53G      3.785      2.317       0.84        313       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.3it/s 3:070.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0226    0.00922     0.0146    0.00417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    121/150      7.83G      3.729      2.268     0.8259          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.4it/s 3:480.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491      0.029     0.0116     0.0196    0.00582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    122/150      9.19G      3.779      2.313     0.8429        489       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:200.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0246    0.00986     0.0148    0.00422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    123/150      8.04G      3.773      2.296     0.8314        202       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.6it/s 3:360.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.6s0.1s\n",
      "                   all        200     127491     0.0251     0.0101     0.0176    0.00523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    124/150      13.6G      3.773       2.32     0.8373        444       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:421.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.7it/s 14.9s0.2s\n",
      "                   all        200     127491     0.0235     0.0094      0.013    0.00344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    125/150      12.2G      3.807      2.315     0.8445         18       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.0it/s 8:301.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0274     0.0108     0.0154     0.0041\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    126/150      7.95G      3.813      2.319      0.843          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.6it/s 4:390.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0239    0.00982     0.0138    0.00372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    127/150      11.7G      3.767      2.324     0.8285          2       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.9it/s 8:401.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.1it/s 14.1s0.2s\n",
      "                   all        200     127491     0.0282     0.0114     0.0176    0.00543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    128/150      9.56G      3.768      2.292     0.8256        544       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.5it/s 2:350.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0244    0.00979     0.0147    0.00429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    129/150      6.97G      3.731      2.286     0.8296        198       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.1it/s 2:440.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0238    0.00957     0.0144    0.00404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    130/150      10.3G       3.78      2.281     0.8354        106       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.4it/s 3:040.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491      0.027     0.0108     0.0169    0.00464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    131/150      9.99G      3.782      2.281     0.8388        139       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.0it/s 3:210.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0235    0.00952     0.0151    0.00479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    132/150      10.7G      3.771      2.293     0.8299         35       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:580.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 2.8it/s 36.2s.7ss\n",
      "                   all        200     127491     0.0233     0.0094     0.0136    0.00374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    133/150      9.07G      3.824      2.316     0.8442        551       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:590.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.5it/s 13.4s0.2s\n",
      "                   all        200     127491     0.0259     0.0104     0.0155    0.00413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    134/150      8.83G      3.754      2.276     0.8303          3       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.3it/s 7:120.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491      0.025    0.00998      0.015    0.00427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    135/150      12.2G      3.818      2.347     0.8253        118       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:590.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0293     0.0116     0.0172    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    136/150      13.7G       3.79      2.322     0.8187        300       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:331.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 14.0s0.1s\n",
      "                   all        200     127491     0.0249    0.00995      0.015     0.0042\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    137/150      13.5G      3.801      2.292     0.8261        465       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:570.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.2s0.1s\n",
      "                   all        200     127491     0.0255     0.0103     0.0153    0.00436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    138/150      10.7G      3.803      2.287      0.817          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:470.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0238    0.00961     0.0144      0.004\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    139/150      9.72G      3.719      2.246     0.8033        508       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:520.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.4it/s 15.7s.1s\n",
      "                   all        200     127491     0.0242    0.00974     0.0146    0.00409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    140/150      10.1G      3.806      2.303     0.8196        415       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:560.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0232    0.00936     0.0141    0.00387\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    141/150      9.75G      3.286      2.065     0.7222          6       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2s/it 19:521.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.2s\n",
      "                   all        200     127491     0.0241    0.00984     0.0136     0.0036\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    142/150      6.94G      3.341      2.065     0.7286        202       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.5it/s 2:340.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.1s\n",
      "                   all        200     127491     0.0225    0.00911     0.0132    0.00354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    143/150      7.09G       3.32      2.044     0.7178        159       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.2it/s 2:190.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.6s0.1s\n",
      "                   all        200     127491     0.0232     0.0095     0.0133     0.0036\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    144/150      12.1G      3.293      2.048     0.7178          2       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.4it/s 6:521.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.2s\n",
      "                   all        200     127491     0.0212    0.00868      0.012    0.00325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    145/150      9.44G       3.31      2.036     0.7219        717       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.8it/s 2:260.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.2s\n",
      "                   all        200     127491     0.0214    0.00866     0.0127    0.00346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    146/150      12.7G      3.314      2.033     0.7258        102       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.5it/s 2:340.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0231    0.00949     0.0132    0.00352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    147/150      12.6G       3.35      2.054     0.7306        327       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.2it/s 3:131.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.2s\n",
      "                   all        200     127491     0.0224    0.00915     0.0129    0.00348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    148/150      8.89G      3.261      2.032     0.7143        184       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.7it/s 2:290.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.1s\n",
      "                   all        200     127491     0.0211     0.0086     0.0122     0.0033\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    149/150      11.5G      3.232      1.983     0.7095        444       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:470.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.2s\n",
      "                   all        200     127491     0.0218    0.00887     0.0126    0.00344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    150/150      10.9G      3.272      2.012     0.7135          8       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:320.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.8s0.2s\n",
      "                   all        200     127491     0.0237    0.00965     0.0144    0.00397\n",
      "\n",
      "150 epochs completed in 14.196 hours.\n",
      "Optimizer stripped from C:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e\\weights\\last.pt, 22.6MB\n",
      "Optimizer stripped from C:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e\\weights\\best.pt, 22.6MB\n",
      "\n",
      "Validating C:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e\\weights\\best.pt...\n",
      "Ultralytics 8.3.230  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 12.7it/s 7.9s.1s\n",
      "                   all        200     127491     0.0304     0.0123     0.0204    0.00688\n",
      "Speed: 0.9ms preprocess, 16.5ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\haas\\data-waves\\img_labeling\\runs\\detect\\03_waves_yolov8s-1000_150e\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022ACA0D9610>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,      0.1544,       0.125,    0.094063,    0.080893,    0.075891,    0.069003,    0.063587,    0.057247,    0.049437,    0.044795,     0.04027,    0.035562,    0.030356,    0.030325,    0.030294,    0.030263,    0.030232,    0.030202,    0.030171,     0.03014,    0.030109,    0.030079,\n",
       "           0.030048,    0.030017,    0.029986,    0.029955,    0.029925,    0.029894,    0.029863,    0.029832,    0.029801,    0.029771,     0.02974,    0.029709,    0.029678,    0.029648,    0.029617,    0.029586,    0.029555,    0.029524,    0.029494,    0.029463,    0.029432,    0.029401,     0.02937,\n",
       "            0.02934,    0.029309,    0.029278,    0.029247,    0.029217,    0.029186,    0.029155,    0.029124,    0.029093,    0.029063,    0.029032,    0.029001,     0.02897,    0.028939,    0.028909,    0.028878,    0.028847,    0.028816,    0.028786,    0.028755,    0.028724,    0.028693,    0.028662,\n",
       "           0.028632,    0.028601,     0.02857,    0.028539,    0.028508,    0.028478,    0.028447,    0.028416,    0.028385,    0.028355,    0.028324,    0.028293,    0.028262,    0.028231,    0.028201,     0.02817,    0.028139,    0.028108,    0.028077,    0.028047,    0.028016,    0.027985,    0.027954,\n",
       "           0.027923,    0.027893,    0.027862,    0.027831,      0.0278,     0.02777,    0.027739,    0.027708,    0.027677,    0.027646,    0.027616,    0.027585,    0.027554,    0.027523,    0.027492,    0.027462,    0.027431,      0.0274,    0.027369,    0.027339,    0.027308,    0.027277,    0.027246,\n",
       "           0.027215,    0.027185,    0.027154,    0.027123,    0.027092,    0.027061,    0.027031,       0.027,    0.026969,    0.026938,    0.026908,    0.026877,    0.026846,    0.026815,    0.026784,    0.026754,    0.026723,    0.026692,    0.026661,     0.02663,      0.0266,    0.026569,    0.026538,\n",
       "           0.026507,    0.026477,    0.026446,    0.026415,    0.026384,    0.026353,    0.026323,    0.026292,    0.026261,     0.02623,    0.026199,    0.026169,    0.026138,    0.026107,    0.026076,    0.026046,    0.026015,    0.025984,    0.025953,    0.025922,    0.025892,    0.025861,     0.02583,\n",
       "           0.025799,    0.025768,    0.025738,    0.025707,    0.025676,    0.025645,    0.025614,    0.025584,    0.025553,    0.025522,    0.025491,    0.025461,     0.02543,    0.025399,    0.025368,    0.025337,    0.025307,    0.025276,    0.025245,    0.025214,    0.025183,    0.025153,    0.025122,\n",
       "           0.025091,     0.02506,     0.02503,    0.024999,    0.024968,    0.024937,    0.024906,    0.024876,    0.024845,    0.024814,    0.024783,    0.024752,    0.024722,    0.024691,     0.02466,    0.024629,    0.024599,    0.024568,    0.024537,    0.024506,    0.024475,    0.024445,    0.024414,\n",
       "           0.024383,    0.024352,    0.024321,    0.024291,     0.02426,    0.024229,    0.024198,    0.024168,    0.024137,    0.024106,    0.024075,    0.024044,    0.024014,    0.023983,    0.023952,    0.023921,     0.02389,     0.02386,    0.023829,    0.023798,    0.023767,    0.023737,    0.023706,\n",
       "           0.023675,    0.023644,    0.023613,    0.023583,    0.023552,    0.023521,     0.02349,    0.023459,    0.023429,    0.023398,    0.023367,    0.023336,    0.023305,    0.023275,    0.023244,    0.023213,    0.023182,    0.023152,    0.023121,     0.02309,    0.023059,    0.023028,    0.022998,\n",
       "           0.022967,    0.022936,    0.022905,    0.022874,    0.022844,    0.022813,    0.022782,    0.022751,    0.022721,     0.02269,    0.022659,    0.022628,    0.022597,    0.022567,    0.022536,    0.022505,    0.022474,    0.022443,    0.022413,    0.022382,    0.022351,     0.02232,     0.02229,\n",
       "           0.022259,    0.022228,    0.022197,    0.022166,    0.022136,    0.022105,    0.022074,    0.022043,    0.022012,    0.021982,    0.021951,     0.02192,    0.021889,    0.021859,    0.021828,    0.021797,    0.021766,    0.021735,    0.021705,    0.021674,    0.021643,    0.021612,    0.021581,\n",
       "           0.021551,     0.02152,    0.021489,    0.021458,    0.021428,    0.021397,    0.021366,    0.021335,    0.021304,    0.021274,    0.021243,    0.021212,    0.021181,     0.02115,     0.02112,    0.021089,    0.021058,    0.021027,    0.020996,    0.020966,    0.020935,    0.020904,    0.020873,\n",
       "           0.020843,    0.020812,    0.020781,     0.02075,    0.020719,    0.020689,    0.020658,    0.020627,    0.020596,    0.020565,    0.020535,    0.020504,    0.020473,    0.020442,    0.020412,    0.020381,     0.02035,    0.020319,    0.020288,    0.020258,    0.020227,    0.020196,    0.020165,\n",
       "           0.020134,    0.020104,    0.020073,    0.020042,    0.020011,    0.019981,     0.01995,    0.019919,    0.019888,    0.019857,    0.019827,    0.019796,    0.019765,    0.019734,    0.019703,    0.019673,    0.019642,    0.019611,     0.01958,     0.01955,    0.019519,    0.019488,    0.019457,\n",
       "           0.019426,    0.019396,    0.019365,    0.019334,    0.019303,    0.019272,    0.019242,    0.019211,     0.01918,    0.019149,    0.019119,    0.019088,    0.019057,    0.019026,    0.018995,    0.018965,    0.018934,    0.018903,    0.018872,    0.018841,    0.018811,     0.01878,    0.018749,\n",
       "           0.018718,    0.018687,    0.018657,    0.018626,    0.018595,    0.018564,    0.018534,    0.018503,    0.018472,    0.018441,     0.01841,     0.01838,    0.018349,    0.018318,    0.018287,    0.018256,    0.018226,    0.018195,    0.018164,    0.018133,    0.018103,    0.018072,    0.018041,\n",
       "            0.01801,    0.017979,    0.017949,    0.017918,    0.017887,    0.017856,    0.017825,    0.017795,    0.017764,    0.017733,    0.017702,    0.017672,    0.017641,     0.01761,    0.017579,    0.017548,    0.017518,    0.017487,    0.017456,    0.017425,    0.017394,    0.017364,    0.017333,\n",
       "           0.017302,    0.017271,    0.017241,     0.01721,    0.017179,    0.017148,    0.017117,    0.017087,    0.017056,    0.017025,    0.016994,    0.016963,    0.016933,    0.016902,    0.016871,     0.01684,     0.01681,    0.016779,    0.016748,    0.016717,    0.016686,    0.016656,    0.016625,\n",
       "           0.016594,    0.016563,    0.016532,    0.016502,    0.016471,     0.01644,    0.016409,    0.016378,    0.016348,    0.016317,    0.016286,    0.016255,    0.016225,    0.016194,    0.016163,    0.016132,    0.016101,    0.016071,     0.01604,    0.016009,    0.015978,    0.015947,    0.015917,\n",
       "           0.015886,    0.015855,    0.015824,    0.015794,    0.015763,    0.015732,    0.015701,     0.01567,     0.01564,    0.015609,    0.015578,    0.015547,    0.015516,    0.015486,    0.015455,    0.015424,    0.015393,    0.015363,    0.015332,    0.015301,     0.01527,    0.015239,    0.015209,\n",
       "           0.015178,    0.015147,    0.015116,    0.015085,    0.015055,    0.015024,    0.014993,    0.014962,    0.014932,    0.014901,     0.01487,    0.014839,    0.014808,    0.014778,    0.014747,    0.014716,    0.014685,    0.014654,    0.014624,    0.014593,    0.014562,    0.014531,    0.014501,\n",
       "            0.01447,    0.014439,    0.014408,    0.014377,    0.014347,    0.014316,    0.014285,    0.014254,    0.014223,    0.014193,    0.014162,    0.014131,      0.0141,    0.014069,    0.014039,    0.014008,    0.013977,    0.013946,    0.013916,    0.013885,    0.013854,    0.013823,    0.013792,\n",
       "           0.013762,    0.013731,      0.0137,    0.013669,    0.013638,    0.013608,    0.013577,    0.013546,    0.013515,    0.013485,    0.013454,    0.013423,    0.013392,    0.013361,    0.013331,      0.0133,    0.013269,    0.013238,    0.013207,    0.013177,    0.013146,    0.013115,    0.013084,\n",
       "           0.013054,    0.013023,    0.012992,    0.012961,     0.01293,      0.0129,    0.012869,    0.012838,    0.012807,    0.012776,    0.012746,    0.012715,    0.012684,    0.012653,    0.012623,    0.012592,    0.012561,     0.01253,    0.012499,    0.012469,    0.012438,    0.012407,    0.012376,\n",
       "           0.012345,    0.012315,    0.012284,    0.012253,    0.012222,    0.012192,    0.012161,     0.01213,    0.012099,    0.012068,    0.012038,    0.012007,    0.011976,    0.011945,    0.011914,    0.011884,    0.011853,    0.011822,    0.011791,     0.01176,     0.01173,    0.011699,    0.011668,\n",
       "           0.011637,    0.011607,    0.011576,    0.011545,    0.011514,    0.011483,    0.011453,    0.011422,    0.011391,     0.01136,    0.011329,    0.011299,    0.011268,    0.011237,    0.011206,    0.011176,    0.011145,    0.011114,    0.011083,    0.011052,    0.011022,    0.010991,     0.01096,\n",
       "           0.010929,    0.010898,    0.010868,    0.010837,    0.010806,    0.010775,    0.010745,    0.010714,    0.010683,    0.010652,    0.010621,    0.010591,     0.01056,    0.010529,    0.010498,    0.010467,    0.010437,    0.010406,    0.010375,    0.010344,    0.010314,    0.010283,    0.010252,\n",
       "           0.010221,     0.01019,     0.01016,    0.010129,    0.010098,    0.010067,    0.010036,    0.010006,   0.0099749,   0.0099441,   0.0099133,   0.0098825,   0.0098517,   0.0098209,   0.0097902,   0.0097594,   0.0097286,   0.0096978,    0.009667,   0.0096362,   0.0096054,   0.0095746,   0.0095439,\n",
       "          0.0095131,   0.0094823,   0.0094515,   0.0094207,   0.0093899,   0.0093591,   0.0093284,   0.0092976,   0.0092668,    0.009236,   0.0092052,   0.0091744,   0.0091436,   0.0091128,   0.0090821,   0.0090513,   0.0090205,   0.0089897,   0.0089589,   0.0089281,   0.0088973,   0.0088666,   0.0088358,\n",
       "           0.008805,   0.0087742,   0.0087434,   0.0087126,   0.0086818,    0.008651,   0.0086203,   0.0085895,   0.0085587,   0.0085279,   0.0084971,   0.0084663,   0.0084355,   0.0084048,    0.008374,   0.0083432,   0.0083124,   0.0082816,   0.0082508,     0.00822,   0.0081892,   0.0081585,   0.0081277,\n",
       "          0.0080969,   0.0080661,   0.0080353,   0.0080045,   0.0079737,    0.007943,   0.0079122,   0.0078814,   0.0078506,   0.0078198,    0.007789,   0.0077582,   0.0077274,   0.0076967,   0.0076659,   0.0076351,   0.0076043,   0.0075735,   0.0075427,   0.0075119,   0.0074812,   0.0074504,   0.0074196,\n",
       "          0.0073888,    0.007358,   0.0073272,   0.0072964,   0.0072656,   0.0072349,   0.0072041,   0.0071733,   0.0071425,   0.0071117,   0.0070809,   0.0070501,   0.0070194,   0.0069886,   0.0069578,    0.006927,   0.0068962,   0.0068654,   0.0068346,   0.0068038,   0.0067731,   0.0067423,   0.0067115,\n",
       "          0.0066807,   0.0066499,   0.0066191,   0.0065883,   0.0065576,   0.0065268,    0.006496,   0.0064652,   0.0064344,   0.0064036,   0.0063728,    0.006342,   0.0063113,   0.0062805,   0.0062497,   0.0062189,   0.0061881,   0.0061573,   0.0061265,   0.0060958,    0.006065,   0.0060342,   0.0060034,\n",
       "          0.0059726,   0.0059418,    0.005911,   0.0058802,   0.0058495,   0.0058187,   0.0057879,   0.0057571,   0.0057263,   0.0056955,   0.0056647,    0.005634,   0.0056032,   0.0055724,   0.0055416,   0.0055108,     0.00548,   0.0054492,   0.0054185,   0.0053877,   0.0053569,   0.0053261,   0.0052953,\n",
       "          0.0052645,   0.0052337,   0.0052029,   0.0051722,   0.0051414,   0.0051106,   0.0050798,    0.005049,   0.0050182,   0.0049874,   0.0049567,   0.0049259,   0.0048951,   0.0048643,   0.0048335,   0.0048027,   0.0047719,   0.0047411,   0.0047104,   0.0046796,   0.0046488,    0.004618,   0.0045872,\n",
       "          0.0045564,   0.0045256,   0.0044949,   0.0044641,   0.0044333,   0.0044025,   0.0043717,   0.0043409,   0.0043101,   0.0042793,   0.0042486,   0.0042178,    0.004187,   0.0041562,   0.0041254,   0.0040946,   0.0040638,   0.0040331,   0.0040023,   0.0039715,   0.0039407,   0.0039099,   0.0038791,\n",
       "          0.0038483,   0.0038175,   0.0037868,    0.003756,   0.0037252,   0.0036944,   0.0036636,   0.0036328,    0.003602,   0.0035713,   0.0035405,   0.0035097,   0.0034789,   0.0034481,   0.0034173,   0.0033865,   0.0033557,    0.003325,   0.0032942,   0.0032634,   0.0032326,   0.0032018,    0.003171,\n",
       "          0.0031402,   0.0031095,   0.0030787,   0.0030479,   0.0030171,   0.0029863,   0.0029555,   0.0029247,   0.0028939,   0.0028632,   0.0028324,   0.0028016,   0.0027708,     0.00274,   0.0027092,   0.0026784,   0.0026477,   0.0026169,   0.0025861,   0.0025553,   0.0025245,   0.0024937,   0.0024629,\n",
       "          0.0024321,   0.0024014,   0.0023706,   0.0023398,    0.002309,   0.0022782,   0.0022474,   0.0022166,   0.0021859,   0.0021551,   0.0021243,   0.0020935,   0.0020627,   0.0020319,   0.0020011,   0.0019703,   0.0019396,   0.0019088,    0.001878,   0.0018472,   0.0018164,   0.0017856,   0.0017548,\n",
       "          0.0017241,   0.0016933,   0.0016625,   0.0016317,   0.0016009,   0.0015701,   0.0015393,   0.0015085,   0.0014778,    0.001447,   0.0014162,   0.0013854,   0.0013546,   0.0013238,    0.001293,   0.0012623,   0.0012315,   0.0012007,   0.0011699,   0.0011391,   0.0011083,   0.0010775,   0.0010467,\n",
       "           0.001016,  0.00098517,  0.00095439,   0.0009236,  0.00089281,  0.00086203,  0.00083124,  0.00080045,  0.00076967,  0.00073888,  0.00070809,  0.00067731,  0.00064652,  0.00061573,  0.00058495,  0.00055416,  0.00052337,  0.00049259,   0.0004618,  0.00043101,  0.00040023,  0.00036944,  0.00033865,\n",
       "         0.00030787,  0.00027708,  0.00024629,  0.00021551,  0.00018472,  0.00015393,  0.00012315,   9.236e-05,  6.1573e-05,  3.0787e-05,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.017485,    0.017485,    0.017585,    0.017647,    0.017707,    0.017747,     0.01779,    0.017807,    0.017849,    0.017887,     0.01791,    0.017873,    0.017883,    0.017917,    0.017943,    0.017952,    0.017969,    0.017974,    0.017958,    0.017896,    0.017835,     0.01784,    0.017804,\n",
       "           0.017797,     0.01778,    0.017714,    0.017645,    0.017569,    0.017465,    0.017469,    0.017432,    0.017359,    0.017246,    0.017187,    0.017077,    0.017007,    0.016779,    0.016496,    0.016431,     0.01624,    0.015987,    0.015674,    0.015349,    0.015122,    0.014872,    0.014637,\n",
       "           0.014399,    0.014057,    0.013687,    0.013256,    0.012946,    0.012493,    0.012069,    0.011522,    0.011136,    0.010776,    0.010333,    0.010079,   0.0096118,   0.0091968,    0.008785,   0.0082586,   0.0080015,   0.0075806,   0.0073012,   0.0070056,   0.0068117,   0.0065105,   0.0062103,\n",
       "          0.0059504,   0.0057647,    0.005623,   0.0055099,    0.005365,   0.0051593,   0.0049981,    0.004896,   0.0047176,   0.0045237,   0.0043586,   0.0042248,   0.0040891,   0.0038759,   0.0037557,   0.0035994,   0.0035146,   0.0034236,   0.0032862,   0.0031645,   0.0030277,    0.002951,   0.0028283,\n",
       "          0.0027362,   0.0025663,   0.0024584,    0.002195,   0.0021026,   0.0020098,   0.0019787,   0.0019486,   0.0019023,   0.0018004,   0.0017007,   0.0016356,   0.0016236,    0.001546,   0.0014839,   0.0013748,   0.0013594,   0.0012973,   0.0012663,   0.0012508,   0.0011884,   0.0011417,   0.0010637,\n",
       "          0.0010481,   0.0010013,  0.00097011,   0.0008764,  0.00087646,  0.00082961,  0.00079836,  0.00078274,  0.00073587,   0.0006733,  0.00064204,  0.00062002,   0.0005795,  0.00054822,   0.0005326,  0.00051698,  0.00051703,  0.00050139,  0.00048575,  0.00048577,  0.00045446,  0.00043881,  0.00042315,\n",
       "         0.00042317,  0.00042319,  0.00040754,  0.00037621,  0.00037623,  0.00033067,  0.00032922,  0.00031355,  0.00029788,  0.00029789,  0.00029789,  0.00029789,  0.00026655,  0.00026655,  0.00026656,  0.00021953,  0.00019438,   0.0001725,   0.0001725,  0.00016716,  0.00015727,  0.00015683,  0.00015683,\n",
       "         0.00015683,  0.00015089,  0.00014333,  0.00014115,  0.00014115,  0.00012455,  0.00010979,  0.00010979,  0.00010979,  0.00010979,  0.00010979,  9.2747e-05,  7.4354e-05,  6.5167e-05,  6.2742e-05,  6.2742e-05,  6.2742e-05,  6.2742e-05,  6.2742e-05,  6.2742e-05,  6.2742e-05,  4.9782e-05,  4.7057e-05,\n",
       "         4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7058e-05,  4.7059e-05,  4.7059e-05,  4.7059e-05,  4.7059e-05,  4.7059e-05,  4.7059e-05,   4.706e-05,   4.706e-05,  4.5311e-05,  4.2574e-05,  3.9837e-05,    3.71e-05,  3.4364e-05,  3.1627e-05,\n",
       "         3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.0934e-05,  2.5341e-05,\n",
       "         1.9748e-05,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.030378,    0.030378,     0.03114,    0.031587,    0.031971,    0.032291,    0.032579,    0.032801,     0.03309,     0.03335,     0.03363,    0.033789,    0.034042,    0.034352,    0.034676,     0.03494,    0.035198,    0.035444,    0.035655,    0.035793,    0.035946,    0.036276,    0.036574,\n",
       "           0.036896,    0.037227,     0.03745,     0.03774,    0.038064,    0.038397,    0.038995,    0.039488,    0.040018,    0.040365,    0.041011,    0.041567,    0.042283,    0.042713,    0.043162,    0.044425,    0.045186,    0.046256,    0.047215,    0.048356,    0.050173,    0.051788,    0.053791,\n",
       "           0.055739,    0.057049,    0.058975,    0.060477,    0.062276,    0.063679,    0.065793,    0.066598,    0.068199,    0.070199,    0.071481,    0.073209,    0.074435,    0.076019,    0.076752,    0.077694,    0.079741,    0.080851,    0.082386,    0.084032,    0.086569,    0.087778,    0.090152,\n",
       "           0.091896,    0.094774,    0.098247,     0.10097,     0.10456,     0.10708,     0.11022,     0.11311,     0.11537,     0.11798,     0.11962,     0.12348,     0.12483,     0.12388,       0.127,     0.12943,     0.13464,     0.13714,      0.1382,      0.1419,     0.14269,     0.14879,     0.15055,\n",
       "            0.15227,      0.1499,     0.15052,     0.14376,     0.14678,     0.14645,     0.15187,     0.15508,     0.15759,     0.15803,     0.15717,     0.16127,      0.1688,      0.1703,     0.17161,     0.16771,     0.17281,     0.17601,     0.18203,     0.18676,     0.18594,     0.18569,     0.18397,\n",
       "             0.1876,     0.18627,     0.18779,     0.18346,     0.18907,     0.18948,     0.18794,     0.18866,     0.18835,     0.18053,     0.18142,     0.18029,     0.17945,     0.18056,     0.18424,      0.1893,     0.20346,     0.20659,     0.21292,     0.21771,     0.21603,     0.22057,     0.21793,\n",
       "            0.22961,     0.24425,     0.24883,     0.24677,     0.26047,     0.24787,     0.25288,     0.25159,     0.25019,     0.25695,     0.26084,     0.26613,     0.26206,     0.26627,     0.27548,     0.26003,     0.24112,     0.23509,     0.24738,     0.24977,      0.2386,     0.25386,     0.26482,\n",
       "             0.2693,      0.2626,     0.25282,     0.25463,     0.26636,     0.25662,     0.24047,      0.2524,     0.25783,     0.28475,     0.30776,     0.31249,     0.26675,     0.24186,     0.25065,     0.25328,     0.25591,     0.25854,     0.26117,     0.26379,     0.26642,     0.22339,     0.23706,\n",
       "            0.25151,     0.25406,     0.25661,     0.25916,     0.26172,     0.26427,     0.26682,     0.26938,     0.27193,      0.3188,     0.36532,      0.3832,     0.39275,      0.4023,     0.41185,      0.4214,     0.45771,     0.48885,      0.4714,     0.45396,     0.43651,     0.41906,     0.40161,\n",
       "            0.40532,     0.41117,     0.41703,     0.42289,     0.42874,      0.4346,     0.44046,     0.44632,     0.45217,     0.45803,     0.46389,     0.46975,      0.4756,     0.48146,     0.48732,     0.49317,     0.49903,     0.55185,     0.61398,     0.69108,     0.85187,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.012275,    0.012275,    0.012252,    0.012244,    0.012244,    0.012236,    0.012236,     0.01222,     0.01222,     0.01222,    0.012205,     0.01215,    0.012126,    0.012119,    0.012103,    0.012079,    0.012064,     0.01204,    0.012001,     0.01193,     0.01186,    0.011828,    0.011766,\n",
       "           0.011726,    0.011679,    0.011601,    0.011515,     0.01142,    0.011303,    0.011256,    0.011185,    0.011083,    0.010965,    0.010871,    0.010746,    0.010644,     0.01044,    0.010197,    0.010079,   0.0098987,   0.0096634,   0.0093967,   0.0091222,   0.0089026,    0.008683,   0.0084712,\n",
       "          0.0082673,   0.0080163,   0.0077417,   0.0074437,    0.007224,    0.006926,   0.0066436,   0.0063063,   0.0060632,   0.0058357,    0.005569,   0.0054121,   0.0051376,   0.0048945,   0.0046592,   0.0043611,   0.0042121,   0.0039768,   0.0038199,   0.0036552,   0.0035453,   0.0033806,   0.0032159,\n",
       "          0.0030747,   0.0029728,   0.0028943,   0.0028322,   0.0027531,   0.0026433,    0.002557,   0.0025021,    0.002408,    0.002306,   0.0022198,   0.0021492,   0.0020786,   0.0019688,    0.001906,   0.0018251,   0.0017805,   0.0017335,   0.0016629,   0.0016001,   0.0015301,   0.0014903,   0.0014276,\n",
       "          0.0013805,   0.0012942,   0.0012393,    0.001106,   0.0010589,   0.0010118,  0.00099584,  0.00098046,  0.00095693,  0.00090537,  0.00085496,  0.00082196,  0.00081574,  0.00077653,  0.00074515,  0.00069024,   0.0006824,  0.00065103,  0.00063534,   0.0006275,  0.00059612,  0.00057259,  0.00053337,\n",
       "         0.00052553,    0.000502,  0.00048631,  0.00043925,  0.00043925,  0.00041572,  0.00040003,  0.00039218,  0.00036865,  0.00033728,  0.00032159,  0.00031054,  0.00029022,  0.00027453,  0.00026669,  0.00025884,  0.00025884,    0.000251,  0.00024315,  0.00024315,  0.00022747,  0.00021962,  0.00021178,\n",
       "         0.00021178,  0.00021178,  0.00020394,  0.00018825,  0.00018825,  0.00016545,  0.00016472,  0.00015687,  0.00014903,  0.00014903,  0.00014903,  0.00014903,  0.00013334,  0.00013334,  0.00013334,  0.00010981,  9.7232e-05,  8.6281e-05,  8.6281e-05,  8.3607e-05,  7.8659e-05,  7.8437e-05,  7.8437e-05,\n",
       "         7.8437e-05,  7.5469e-05,  7.1686e-05,  7.0593e-05,  7.0593e-05,  6.2292e-05,  5.4906e-05,  5.4906e-05,  5.4906e-05,  5.4906e-05,  5.4906e-05,  4.6381e-05,  3.7182e-05,  3.2588e-05,  3.1375e-05,  3.1375e-05,  3.1375e-05,  3.1375e-05,  3.1375e-05,  3.1375e-05,  3.1375e-05,  2.4894e-05,  2.3531e-05,\n",
       "         2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.2657e-05,  2.1288e-05,   1.992e-05,  1.8551e-05,  1.7183e-05,  1.5814e-05,\n",
       "         1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5467e-05,  1.2671e-05,\n",
       "         9.8742e-06,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.006875901783998541)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([  0.0068759])\n",
       "names: {0: 'wave'}\n",
       "nt_per_class: array([127491])\n",
       "nt_per_image: array([190])\n",
       "results_dict: {'metrics/precision(B)': 0.0303783217190442, 'metrics/recall(B)': 0.012275376301072232, 'metrics/mAP50(B)': 0.02036762301906162, 'metrics/mAP50-95(B)': 0.006875901783998541, 'fitness': 0.006875901783998541}\n",
       "save_dir: WindowsPath('C:/haas/data-waves/img_labeling/runs/detect/03_waves_yolov8s-1000_150e')\n",
       "speed: {'preprocess': 0.9374929998375592, 'inference': 16.461033999803476, 'loss': 0.020022000244352967, 'postprocess': 3.4686625004178495}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Give a name to the run\n",
    "run_name = \"03_waves_yolov8s-1000_150e\"\n",
    "\n",
    "# Fine-tune the model\n",
    "base_model.train(\n",
    "    data=data_yaml_path,\n",
    "    device = device,\n",
    "    epochs=150,\n",
    "    imgsz=(512, 2048), #(1024,5069) - time limit exceeded, not enough comutational performance on cpu.\n",
    "    batch=1,\n",
    "    name=run_name,\n",
    "    patience=0,\n",
    "    save=True\n",
    "    #amp=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c9db6f0-c5b4-4905-aeae-b9b535252359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of runs/detect: ['.ipynb_checkpoints', '01_waves_yolov8n-500', '02_waves_yolov8n-1000', '02_waves_yolov8n-1000_150e', '03_waves_yolov8s-1000_150e', 'eval_base', 'eval_base_01_waves_yolov8n', 'eval_finetuned_01', 'eval_finetuned_01_waves_yolov8n', 'wave1_yolov8n', 'wave1_yolov8n2', 'wave1_yolov8n3', 'wave1_yolov8n4', 'wave1_yolov8n5', 'wave1_yolov8n6', 'wave1_yolov8n7']\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents of runs/detect:\", os.listdir(\"runs/detect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3520e6e-7675-4a34-acf2-5f2488859567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce MX450, 2048MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2247.6176.0 MB/s, size: 2362.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images.cache... 200 images, 10 backgrounds, 0 corrupt:\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [02:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        200     127491     0.0311     0.0126     0.0207    0.00619\n",
      "Speed: 5.1ms preprocess, 799.9ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val52\u001b[0m\n",
      "{'metrics/precision(B)': np.float64(0.031071691961339905), 'metrics/recall(B)': np.float64(0.01255774917445153), 'metrics/mAP50(B)': np.float64(0.020732190950238875), 'metrics/mAP50-95(B)': np.float64(0.006190454152466257), 'fitness': np.float64(0.007644627832243519)}\n"
     ]
    }
   ],
   "source": [
    "# rerun the missing validation step only to get metrics\n",
    "\n",
    "model_03_waves_yolov8s_1000_150e = YOLO(\"03_waves_yolov8s-1000_150e.pt\")  #last weights from 05_waves_yolov8s-5000_150e to run the validation process\n",
    "results = model_03_waves_yolov8s_1000_150e.val(data=data_yaml_path,device = device, imgsz=2048, split=\"val\")\n",
    "print(results.results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef39f9-e9b9-4035-af71-aa9527e72d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd88f8-98a6-4806-9721-a19f1c6788b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb611eec-31d0-46f2-a9d6-5e1344ed47e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96b268-478b-463c-9960-25753c3aab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664853a-1b96-4611-90fe-c4b8c5644415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9bfcc-602f-4202-8527-f81ce0dd278c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a328aaf-6acf-4cc1-847b-2459ed9f86a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
