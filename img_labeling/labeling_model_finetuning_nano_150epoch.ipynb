{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef44b6ee-b30b-4809-ad0b-a47410506127",
   "metadata": {},
   "source": [
    "# Image Labeling & Model Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc9c2c-2d77-4f5d-a8cc-5a5763179e08",
   "metadata": {},
   "source": [
    "## 1. Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8d3a3d-e0d1-4fb6-b276-356ac16aaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8d6134-91fa-496c-aa04-b3704f3f33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718ef1da-295a-4c15-874f-5aeab18fb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2096e6-0dbe-486d-a04e-b5ec3b1abdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b046e1b8-2a40-4d4a-aaa9-b4c471a56953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf86f6eb-ac7b-4c10-bcb0-7b19c8a60066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47159055-f2ac-45a6-936f-ab136687d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "from ultralytics.data import utils as data_utils\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9a91df-ae56-49c9-ae32-7fea201abdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4c3159-a524-404f-8f31-b7b33e452fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab7903-0616-4203-b290-6369b94a4471",
   "metadata": {},
   "source": [
    "## 2. Define Paths to Folders & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cbb0b4-6bbc-40d8-8f25-27b2686ae917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source images located in: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up one level to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Set path for the source folder (you can adjust as needed)\n",
    "source_folder = os.path.join(parent_dir, \"idx_images\")\n",
    "labeling_folder = os.path.join(parent_dir, \"img_labeling\")\n",
    "\n",
    "csv_out_path = os.path.join(source_folder, \"image_metadata_weather.csv\")\n",
    "csv_train = os.path.join(labeling_folder, \"train_for_training.csv\")\n",
    "csv_test = os.path.join(labeling_folder, \"test_for_training.csv\")\n",
    "csv_val = os.path.join(labeling_folder, \"val_for_training.csv\")\n",
    "\n",
    "print(f\"Source images located in: {source_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630c9e6d-73c1-4eaa-98d9-1a8a90d52bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted([f for f in os.listdir(source_folder) if f.endswith('.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f391b779-461a-473d-978b-a28d083bd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27592 images found\n"
     ]
    }
   ],
   "source": [
    "print(len(image_files), \"images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a249e63e-0851-4e09-a00a-a1d0dc84ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO model (load once)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f3473-41de-4c04-8240-1389b2d1cab9",
   "metadata": {},
   "source": [
    "## 3. Finetuning YOLO Model using stratified Train, Test, Val set and created labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21fe4fb-2a5a-4607-a57c-4665e36e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset root where YOLO dataset will be automatically created\n",
    "dataset_root = os.path.join(parent_dir, \"waves_yolo_dataset_1000_nano\")\n",
    "os.makedirs(dataset_root, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d0c694-0396-4629-a0e2-69f570911382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lists of image names\n",
    "# -------------------------------------------------------------\n",
    "def load_image_list(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"new_image_name\" in df.columns:\n",
    "        col = \"new_image_name\"\n",
    "    elif \"image_name\" in df.columns:\n",
    "        col = \"image_name\"\n",
    "    else:\n",
    "        raise ValueError(f\"No image name column in {csv_path}\")\n",
    "    return df[col].dropna().astype(str).tolist()\n",
    "\n",
    "# Load ALL images from CSVs\n",
    "train_imgs_full = load_image_list(csv_train)\n",
    "val_imgs_full   = load_image_list(csv_val)\n",
    "test_imgs_full  = load_image_list(csv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84336701-1cb7-44a5-a0bf-d70149e3d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset: train=1000, val=200, test=200\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Subsample: 500 train, 200 val, 200 test\n",
    "# (shuffled so you don't just get the first rows)\n",
    "# -------------------------------------------------------------\n",
    "random.seed(42)  # for reproducibility\n",
    "\n",
    "train_imgs = random.sample(train_imgs_full, min(1000, len(train_imgs_full)))\n",
    "val_imgs   = random.sample(val_imgs_full,  min(200, len(val_imgs_full)))\n",
    "test_imgs  = random.sample(test_imgs_full, min(200, len(test_imgs_full)))\n",
    "\n",
    "print(f\"Using subset: train={len(train_imgs)}, val={len(val_imgs)}, test={len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3afe552c-a9a9-44ea-9d21-f46d6a17710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote split files:\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\train.txt\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\val.txt\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# Write YOLO split txt files with ABSOLUTE PATHS\n",
    "# -------------------------------------------------------------\n",
    "def write_split_file(img_list, out_path):\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for name in img_list:\n",
    "            full_path = os.path.abspath(os.path.join(source_folder, name))\n",
    "            f.write(full_path + \"\\n\")\n",
    "\n",
    "train_txt = os.path.join(dataset_root, \"train.txt\")\n",
    "val_txt   = os.path.join(dataset_root, \"val.txt\")\n",
    "test_txt  = os.path.join(dataset_root, \"test.txt\")\n",
    "\n",
    "write_split_file(train_imgs, train_txt)\n",
    "write_split_file(val_imgs, val_txt)\n",
    "write_split_file(test_imgs, test_txt)\n",
    "\n",
    "print(\"Wrote split files:\")\n",
    "print(train_txt)\n",
    "print(val_txt)\n",
    "print(test_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6cf582-3197-45fe-8414-29c5f197c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data.yaml at: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\01_waves.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create YOLO data.yaml\n",
    "# IMPORTANT: 'path' tells YOLO where labels live.\n",
    "# -------------------------------------------------------------\n",
    "# Normalize Windows paths before inserting into f-string\n",
    "train_txt_norm = train_txt.replace(\"\\\\\", \"/\")\n",
    "val_txt_norm   = val_txt.replace(\"\\\\\", \"/\")\n",
    "test_txt_norm  = test_txt.replace(\"\\\\\", \"/\")\n",
    "parent_dir_norm = parent_dir.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Create YOLO data.yaml\n",
    "data_yaml_path = os.path.join(dataset_root, \"01_waves.yaml\")\n",
    "\n",
    "yaml_text = f\"\"\"\n",
    "# Dataset config without copying images\n",
    "\n",
    "train: {train_txt_norm}\n",
    "val: {val_txt_norm}\n",
    "test: {test_txt_norm}\n",
    "\n",
    "names:\n",
    "  0: wave\n",
    "nc: 1\n",
    "\"\"\"\n",
    "\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "print(\"Created data.yaml at:\", data_yaml_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d969d-af64-4f67-aba9-911b3fbdc2df",
   "metadata": {},
   "source": [
    "##### Load model and checking if model finds labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1cb12c-e561-4c42-bb6b-675061544355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train source: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\train.txt\n",
      "Val source:   C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\val.txt\n",
      "Test source:  C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model first try nano than small or medium\n",
    "base_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "info = data_utils.check_det_dataset(data_yaml_path)\n",
    "print(\"Train source:\", info[\"train\"])\n",
    "print(\"Val source:  \", info[\"val\"])\n",
    "print(\"Test source: \", info[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d2c49e1-55fe-4a15-9ac5-0d5e4c59aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing train labels: 1000\n",
      "Missing val labels:   200\n",
      "Missing test labels:  200\n",
      "Example missing label: ['img_14237.txt', 'img_15383.txt', 'img_04648.txt', 'img_16453.txt', 'img_06242.txt']\n"
     ]
    }
   ],
   "source": [
    "def count_missing_labels(txt_file, label_folder):\n",
    "    missing = []\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:\n",
    "            img_path = line.strip()\n",
    "            img_name = Path(img_path).name\n",
    "            label_name = img_name.replace(\".png\", \".txt\")\n",
    "            label_path = Path(label_folder) / label_name\n",
    "            if not label_path.exists():\n",
    "                missing.append(label_name)\n",
    "    return missing\n",
    "\n",
    "labels_folder = r\"C:/Users/A/Documents/XX_GitHub_Repo/data-waves/labels\"\n",
    "\n",
    "missing_train = count_missing_labels(info[\"train\"], labels_folder)\n",
    "missing_val   = count_missing_labels(info[\"val\"], labels_folder)\n",
    "missing_test  = count_missing_labels(info[\"test\"], labels_folder)\n",
    "\n",
    "print(\"Missing train labels:\", len(missing_train))\n",
    "print(\"Missing val labels:  \", len(missing_val))\n",
    "print(\"Missing test labels: \", len(missing_test))\n",
    "\n",
    "if missing_train:\n",
    "    print(\"Example missing label:\", missing_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c884d-0006-412c-b516-0e282cea4496",
   "metadata": {},
   "source": [
    "##### Run finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0008cb-a5dc-4d34-b965-4d395e164bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA is available. Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Device selection (GPU if available, else CPU)\n",
    "# ------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = 0  # GPU index for ultralytics (0 = first GPU)\n",
    "    print(\"✅ CUDA is available. Training on GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"⚠️ CUDA not available. Training on CPU (slower).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08344f72-3e75-432d-811c-89055e769b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.230  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\haas\\data-waves\\waves_yolo_dataset_1000_nano\\01_waves.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=(512, 2048), int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=02_waves_yolov8n-1000_150e, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING updating to 'imgsz=2048'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1890.5283.5 MB/s, size: 2393.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\haas\\data-waves\\idx_images... 1000 images, 62 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 447.6it/s 2.2s1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\haas\\data-waves\\idx_images.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1096.5152.8 MB/s, size: 2424.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\haas\\data-waves\\idx_images... 200 images, 10 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 168.4it/s 1.2s.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\haas\\data-waves\\idx_images.cache\n",
      "Plotting labels to C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 2048 train, 2048 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/150      13.6G      4.218      13.11     0.9042          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:530.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.6s0.2s\n",
      "                   all        200     127491    0.00163   0.000769   0.000835    0.00016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/150      6.37G      4.149      7.295      0.853        438       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.2it/s 1:490.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491    0.00557    0.00262    0.00281   0.000603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/150      8.63G       4.19      5.092     0.8537         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491    0.00873    0.00411    0.00456    0.00106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/150      6.53G      4.182      4.018     0.8582        277       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.2it/s 7:270.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491       0.01    0.00472    0.00519     0.0012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/150      8.24G      4.102      3.628     0.8376         19       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.4it/s 3:460.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491    0.00985    0.00399     0.0099    0.00311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/150      9.99G      4.174       3.24     0.8572        552       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.5it/s 1:570.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 4.8it/s 21.0s.6s\n",
      "                   all        200     127491    0.00855    0.00375    0.00525    0.00139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/150      11.8G      4.203      3.166     0.8594        134       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491    0.00781    0.00304    0.00638    0.00238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/150      12.8G      4.163      3.002      0.851         36       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0174    0.00714    0.00959    0.00222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/150      12.6G      4.118      2.861     0.8494        199       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.3it/s 3:520.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0113    0.00442    0.00591    0.00138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/150      8.57G      4.137      2.883     0.8458        317       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:120.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0181    0.00689    0.00933    0.00226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/150      12.2G      4.142      2.925     0.8532        259       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:120.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0184    0.00783    0.00958    0.00232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/150      5.28G      4.103      2.695     0.8433        193       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491    0.00799    0.00341     0.0048    0.00127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/150      9.54G      4.111      2.738     0.8458          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.6it/s 6:180.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0167    0.00688    0.00992    0.00235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/150      5.69G      4.104      2.676     0.8414        337       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.9it/s 2:060.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.2it/s 12.2s0.2s\n",
      "                   all        200     127491     0.0145    0.00612    0.00838    0.00191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/150      8.24G      4.187       2.77     0.8564        464       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.7it/s 6:131.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.2it/s 12.2s0.2s\n",
      "                   all        200     127491     0.0159    0.00667    0.00959     0.0022\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/150      9.21G      4.112      2.702     0.8447        135       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.3it/s 2:01<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0117    0.00477    0.00631    0.00159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/150        12G      4.097      2.691     0.8413        618       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.9it/s 8:471.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0135    0.00555    0.00841     0.0026\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/150      8.12G      4.036      2.711      0.833         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:580.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0151    0.00624       0.01    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/150      12.8G      4.118      2.694     0.8486       1055       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.0it/s 2:240.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0167    0.00671     0.0105    0.00309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/150      8.37G      4.048      2.621     0.8422        184       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.9it/s 8:590.4s6\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.1s\n",
      "                   all        200     127491     0.0185    0.00826     0.0115    0.00332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/150      7.23G      4.077      2.724      0.841        564       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.8it/s 2:270.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0108    0.00435    0.00788    0.00196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/150      7.66G      4.082      2.606     0.8432         94       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.1it/s 1:50<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.1s\n",
      "                   all        200     127491     0.0116    0.00449    0.00659     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/150      8.32G      4.014      2.656     0.8321         46       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.1it/s 2:43<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0178    0.00729     0.0103    0.00264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/150      13.9G      4.054      2.599     0.8423        411       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.0it/s 15:551.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0119    0.00497    0.00734    0.00218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/150        10G      4.034      2.551     0.8355        216       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.8it/s 2:090.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0149    0.00644    0.00909    0.00231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/150      7.21G      4.092      2.672     0.8504        188       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.9it/s 2:25.5ssss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.6it/s 13.1s0.1s\n",
      "                   all        200     127491      0.011    0.00446    0.00651    0.00192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/150      12.7G      3.985      2.596     0.8338        258       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.7it/s 2:280.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0246     0.0102      0.014    0.00335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/150      11.2G      4.033      2.616       0.84         95       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:130.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0113     0.0047    0.00661    0.00161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/150       6.9G      4.075      2.563     0.8507        113       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:110.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0137    0.00566    0.00805    0.00191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/150      12.2G      4.085      2.605     0.8515        486       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:060.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.1s\n",
      "                   all        200     127491     0.0225    0.00948     0.0127    0.00296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/150      7.25G      4.025      2.616      0.842        946       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:120.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0138    0.00583     0.0077    0.00196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/150      12.8G       4.06      2.583     0.8508        564       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.5it/s 11:140.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0197    0.00801      0.012     0.0029\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/150      9.11G      4.074       2.56     0.8539        394       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.2it/s 2:190.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0161     0.0066    0.00904    0.00262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/150      10.8G      3.998      2.492     0.8353        220       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.3it/s 7:060.5s7\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0151    0.00642    0.00845    0.00229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/150      12.8G      3.996      2.563     0.8377        246       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:600.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0159    0.00624     0.0089     0.0024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/150      13.5G      4.024      2.532     0.8414         96       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:050.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0138    0.00573    0.00776    0.00191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/150      6.58G      3.998      2.576     0.8332        537       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.2it/s 1:490.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0236    0.00984     0.0136    0.00344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/150      12.6G      3.983       2.58     0.8318        191       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.4it/s 2:150.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0172    0.00715     0.0105    0.00259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/150      10.9G      3.973      2.509     0.8318        292       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.4it/s 2:370.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0132    0.00544    0.00845    0.00231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/150      7.07G      4.026      2.543     0.8425         22       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.3it/s 2:400.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0161    0.00665      0.013      0.005\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/150      7.36G      4.027        2.5     0.8457        147       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.0it/s 1:510.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0231    0.00972     0.0134    0.00342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/150      6.27G      3.967      2.497     0.8354         29       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.1it/s 2:210.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0188    0.00771     0.0119    0.00354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/150      8.43G      3.982      2.533      0.842          8       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.8it/s 1:54<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0129    0.00548     0.0114    0.00452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/150      7.07G      4.013      2.552      0.848        298       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:110.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0166     0.0072     0.0108    0.00325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/150      12.2G      3.985      2.535     0.8407         78       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.4it/s 6:570.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0177    0.00735     0.0113    0.00381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/150      11.4G      3.974      2.497     0.8329         75       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.8it/s 2:080.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0134    0.00569    0.00794    0.00207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/150      9.87G      3.989      2.473     0.8363        172       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.3it/s 2:010.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491      0.015    0.00617    0.00912    0.00254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/150      10.3G       4.04      2.595     0.8451        194       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:590.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0118    0.00484    0.00659     0.0016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/150      7.56G      4.037      2.558     0.8438        431       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.0it/s 1:510.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.4it/s 18.5s.5s\n",
      "                   all        200     127491     0.0186    0.00779     0.0111    0.00322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/150      12.5G      4.005       2.48     0.8399        171       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.2it/s 2:18<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.5it/s 13.3s0.2s\n",
      "                   all        200     127491      0.015    0.00624    0.00874     0.0023\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/150      9.28G      3.966      2.501     0.8358         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0181    0.00721       0.01    0.00266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/150      6.37G      3.941      2.473     0.8343         26       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.5it/s 3:430.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491      0.015    0.00611    0.00845    0.00233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/150        13G      3.858      2.416     0.8176        843       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.3it/s 2:160.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0161     0.0067    0.00907    0.00239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/150      7.14G      3.917      2.487     0.8285        319       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:590.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0183    0.00728     0.0106    0.00289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/150        12G      3.946      2.473     0.8329        452       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.8it/s 2:080.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0234    0.00956     0.0134    0.00351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/150      12.1G      3.976      2.463       0.84         13       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:03<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0259     0.0106     0.0147    0.00374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/150      13.3G      3.898      2.427     0.8199          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.3it/s 2:170.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0191    0.00789     0.0104    0.00263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/150      9.82G      3.926      2.456     0.8275        225       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.6it/s 1:570.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0236     0.0098      0.013     0.0034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/150      13.1G      3.954      2.492     0.8393        416       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.3it/s 2:010.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0161     0.0066    0.00884    0.00225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/150        11G      3.928       2.44     0.8289        387       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.7it/s 2:300.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0174    0.00704    0.00928    0.00236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/150      13.8G      3.933      2.461      0.825        188       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:140.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0169    0.00692    0.00944    0.00234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/150      12.5G      3.912       2.43     0.8302        675       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.8it/s 2:260.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0239    0.00951     0.0144    0.00342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/150      11.9G      3.911       2.42     0.8229          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.8it/s 2:08<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0238    0.00991     0.0128    0.00324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/150      13.5G      3.939      2.419     0.8269        189       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.1it/s 3:151.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0158    0.00646    0.00894    0.00228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/150      12.3G      3.927      2.441     0.8291        287       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.8it/s 2:260.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0204    0.00839     0.0113    0.00293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/150      9.59G      3.924      2.409     0.8313        170       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.7it/s 1:550.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 4.6it/s 21.6s.6s\n",
      "                   all        200     127491     0.0221    0.00896     0.0119    0.00301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/150      9.97G      3.938       2.44      0.832        351       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:090.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491      0.017    0.00704     0.0101    0.00252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/150      12.1G       3.93      2.409     0.8329        129       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:100.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0145    0.00606    0.00847    0.00209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/150      6.27G      3.917      2.416     0.8309       1383       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.0it/s 1:520.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.5it/s 18.2s.5s\n",
      "                   all        200     127491     0.0233    0.00942     0.0128    0.00335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/150      9.51G      3.921       2.44     0.8291        268       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.1it/s 2:430.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0239    0.00981     0.0144    0.00393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/150      11.5G      3.936      2.428     0.8297         43       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.6it/s 10:310.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0193     0.0081     0.0146    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/150      7.47G      3.958      2.407     0.8305        204       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.2it/s 2:190.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0165     0.0071    0.00971    0.00241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/150      12.6G      3.913      2.396     0.8315        570       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2it/s 14:251.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0173    0.00729    0.00973    0.00243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/150      13.1G      3.916      2.398       0.83        587       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.9it/s 2:060.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491      0.023    0.00959     0.0123    0.00305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/150      5.62G      3.988      2.423     0.8495        232       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.3it/s 2:180.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0179    0.00735     0.0108     0.0028\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/150      8.17G      3.988       2.44     0.8406        332       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.3it/s 3:080.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.6it/s 13.1s0.2s\n",
      "                   all        200     127491     0.0249     0.0104     0.0144    0.00367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/150       7.5G      3.898      2.464     0.8261          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.8it/s 6:010.4s5\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.6it/s 13.2s0.1s\n",
      "                   all        200     127491     0.0203    0.00835     0.0114    0.00295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/150      7.57G      3.924      2.402     0.8276        298       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.9it/s 1:530.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.3it/s 19.0s.5s\n",
      "                   all        200     127491     0.0172    0.00702     0.0104    0.00278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/150      7.68G      3.931      2.442     0.8349          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.9it/s 1:52<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0174    0.00725     0.0108    0.00291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/150        11G      3.898      2.407      0.823        317       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.9it/s 2:250.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.8s.1s\n",
      "                   all        200     127491      0.019    0.00778     0.0115    0.00301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/150      13.8G      3.921      2.435     0.8269        160       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:110.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.3it/s 13.7s0.2s\n",
      "                   all        200     127491     0.0227    0.00951     0.0131    0.00328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/150      8.25G      3.938      2.433     0.8315         88       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.9it/s 2:070.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0166     0.0068    0.00971     0.0024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/150      11.6G      3.915      2.407     0.8316        392       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.0it/s 2:230.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491       0.02    0.00819     0.0117    0.00324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/150      9.24G      3.876      2.357     0.8218        264       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.1it/s 7:510.6s8\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0251     0.0101      0.014    0.00364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/150      12.1G      3.886      2.445     0.8203        169       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.1it/s 2:040.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0253     0.0102     0.0146    0.00409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/150       7.4G      3.863      2.388     0.8131          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.1it/s 1:500.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.5it/s 18.3s.5s\n",
      "                   all        200     127491     0.0206    0.00846     0.0124    0.00325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/150      7.02G      3.937      2.399     0.8318        508       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.2it/s 2:190.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0226    0.00949     0.0135    0.00348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/150      11.9G      3.896      2.359     0.8263        333       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.9it/s 8:561.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0217    0.00873      0.013    0.00349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/150      5.62G      3.879      2.369     0.8232          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.4it/s 2:160.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0247       0.01     0.0138    0.00372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/150      10.6G      3.884      2.363     0.8212        420       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.3it/s 1:600.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0224    0.00915     0.0129    0.00356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/150      5.86G      3.815      2.389     0.8077          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:580.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0213    0.00872     0.0121    0.00326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/150        12G      3.931      2.427     0.8305        357       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:130.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.7it/s 13.0s0.2s\n",
      "                   all        200     127491     0.0188    0.00784     0.0112    0.00285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/150      7.54G      3.857      2.367     0.8213        741       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.8it/s 2:280.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.7it/s 13.0s0.2s\n",
      "                   all        200     127491     0.0189    0.00766      0.011    0.00283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/150      12.8G      3.908      2.375     0.8216        516       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.3it/s 13:021.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.8s0.2s\n",
      "                   all        200     127491     0.0271     0.0109     0.0161    0.00437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/150      13.6G       3.89      2.398     0.8243        276       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.9it/s 2:060.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.7it/s 12.9s0.2s\n",
      "                   all        200     127491     0.0268     0.0109      0.016     0.0046\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/150       8.2G      3.897      2.372     0.8314        744       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.1it/s 2:040.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.6it/s 13.1s0.2s\n",
      "                   all        200     127491     0.0249     0.0102     0.0155     0.0044\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/150      5.59G      3.927      2.408      0.833        160       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.0it/s 1:510.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0196    0.00799     0.0118     0.0029\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/150      9.61G      3.893      2.401     0.8264        180       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.7it/s 2:280.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.1s\n",
      "                   all        200     127491     0.0174    0.00733    0.00985    0.00262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/150      13.4G      3.863      2.345     0.8153         55       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.1it/s 2:040.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.1s\n",
      "                   all        200     127491     0.0225     0.0091     0.0127    0.00349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/150      8.35G      3.899      2.365     0.8247         92       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:05<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 9.8it/s 10.2s0.2s\n",
      "                   all        200     127491     0.0259     0.0105     0.0155    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    101/150      11.7G       3.91      2.386     0.8316        217       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.5it/s 10:470.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 3.8it/s 26.4s.3ss\n",
      "                   all        200     127491     0.0197    0.00801     0.0123    0.00321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    102/150        10G      3.869      2.353     0.8206         24       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:050.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0253     0.0102     0.0152    0.00435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    103/150      10.3G      3.857      2.364     0.8195        289       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:06<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0232    0.00939     0.0136    0.00373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    104/150      13.8G      3.862       2.35     0.8179          5       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.1s/it 18:491.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0189    0.00774     0.0114    0.00289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    105/150      10.8G      3.892       2.36     0.8264        183       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.3it/s 2:010.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0281     0.0116     0.0159    0.00416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    106/150      6.65G      3.876      2.396     0.8223        321       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491      0.022    0.00908      0.013    0.00364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    107/150      13.6G      3.877      2.345     0.8193        389       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.2it/s 2:190.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0198    0.00813     0.0114     0.0031\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    108/150      9.79G      3.874      2.338     0.8261        120       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.1it/s 2:201.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.1s\n",
      "                   all        200     127491     0.0255     0.0104     0.0142    0.00382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    109/150      10.4G      3.891      2.363      0.824        120       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.8it/s 1:540.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.3it/s 18.8s.5s\n",
      "                   all        200     127491     0.0222    0.00908     0.0128    0.00353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    110/150       8.3G      3.872      2.335     0.8292       1393       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0208    0.00858     0.0119    0.00309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    111/150      5.86G      3.888      2.358     0.8307        425       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.3it/s 2:160.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.1s\n",
      "                   all        200     127491     0.0236     0.0096     0.0134    0.00365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    112/150      12.3G      3.858      2.352     0.8181        118       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.7it/s 9:510.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491      0.021    0.00862     0.0115    0.00286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    113/150      10.3G      3.847      2.352     0.8206         56       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:060.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.6it/s 13.1s0.1s\n",
      "                   all        200     127491     0.0219    0.00909     0.0124    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    114/150      9.09G      3.942      2.372     0.8355         19       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:120.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0223     0.0092     0.0137    0.00376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    115/150      7.83G      3.871      2.332     0.8275        314       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.7it/s 2:300.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0218    0.00891     0.0129    0.00316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    116/150      13.3G      3.901      2.355     0.8294         21       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.5it/s 2:33<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0206     0.0086      0.012    0.00316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    117/150      12.9G      3.852      2.371     0.8185       1082       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.4it/s 2:370.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0218    0.00897     0.0122    0.00315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    118/150      9.44G      3.859       2.34     0.8214        430       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.8it/s 1:540.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.8s0.1s\n",
      "                   all        200     127491     0.0233    0.00947     0.0129    0.00334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    119/150      5.62G      3.855      2.329     0.8236        144       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.1it/s 2:040.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0219    0.00875     0.0122    0.00309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    120/150      13.9G      3.866      2.333     0.8294        313       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2s/it 19:261.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.8s0.1s\n",
      "                   all        200     127491     0.0202    0.00838     0.0113    0.00293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    121/150      6.79G      3.798      2.283      0.812          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:130.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0259     0.0106     0.0143    0.00363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    122/150      8.18G      3.867      2.319     0.8301        489       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.0it/s 8:300.8s5\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0239    0.00955     0.0133    0.00338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    123/150        13G      3.838        2.3     0.8184        202       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:100.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.1s\n",
      "                   all        200     127491     0.0234    0.00952     0.0129    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    124/150      12.6G      3.854      2.316     0.8239        444       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:120.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0226    0.00915     0.0124    0.00307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    125/150      11.2G      3.874      2.319       0.83         18       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.0it/s 5:381.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0231    0.00926     0.0129     0.0034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    126/150      6.93G      3.898      2.319     0.8304          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:110.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0236     0.0097     0.0132    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    127/150      10.7G      3.848       2.31     0.8157          2       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.7it/s 6:090.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0249     0.0102     0.0142    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    128/150      8.55G      3.842      2.307     0.8155        544       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.9it/s 1:520.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.3it/s 19.0s.5s\n",
      "                   all        200     127491      0.023    0.00932      0.014    0.00448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    129/150        13G      3.798      2.262     0.8157        198       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:320.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491      0.024    0.00969      0.014    0.00416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    130/150      9.32G      3.857      2.296     0.8236        106       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.4it/s 2:150.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0258     0.0104     0.0146    0.00405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    131/150      6.86G      3.861        2.3     0.8259        139       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:140.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0238    0.00964      0.013    0.00337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    132/150      9.71G      3.851      2.287     0.8183         35       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.3it/s 13:161.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0216    0.00878     0.0123    0.00313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    133/150      8.06G      3.895      2.311     0.8306        551       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:130.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 9.5it/s 10.5s0.2s\n",
      "                   all        200     127491     0.0212    0.00864     0.0121    0.00326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    134/150      13.6G      3.819      2.272     0.8194          3       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.2it/s 14:201.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0251     0.0101     0.0136    0.00356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    135/150      11.2G      3.868      2.335     0.8229        118       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:590.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0252     0.0101     0.0137    0.00349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    136/150      12.7G      3.838      2.311      0.818        300       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.0it/s 2:230.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0217    0.00876     0.0119    0.00311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    137/150      12.5G      3.856      2.291     0.8278        465       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:010.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0218    0.00893      0.012    0.00315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    138/150      9.48G      3.839       2.28     0.8174          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.8it/s 1:540.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0228    0.00919     0.0127    0.00348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    139/150      8.71G      3.761       2.25     0.8054        508       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:600.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491      0.023    0.00938     0.0127    0.00338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    140/150      7.38G      3.844      2.304     0.8228        415       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:050.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0231    0.00944      0.013     0.0035\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    141/150      8.63G      3.318      2.047     0.7265          6       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.0it/s 8:320.7s4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0225    0.00918     0.0129    0.00329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    142/150        13G      3.376      2.059     0.7301        202       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.9it/s 1:53<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0217    0.00884     0.0121    0.00306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    143/150      6.07G       3.34      2.035     0.7201        159       2048: 100% ━━━━━━━━━━━━ 1000/1000 10.1it/s 1:39.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.3it/s 18.8s.5s\n",
      "                   all        200     127491     0.0233    0.00955     0.0126    0.00353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    144/150        11G      3.339      2.041      0.722          2       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.8it/s 1:540.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0216    0.00885     0.0125    0.00344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    145/150      8.43G      3.344      2.027      0.725        717       2048: 100% ━━━━━━━━━━━━ 1000/1000 10.0it/s 1:40.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.1s\n",
      "                   all        200     127491      0.021    0.00859     0.0113    0.00279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    146/150      11.8G      3.339      2.026     0.7265        102       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.4it/s 1:470.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.1s\n",
      "                   all        200     127491     0.0216    0.00886     0.0117    0.00286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    147/150      11.7G      3.373      2.052     0.7315        327       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0222    0.00901     0.0121    0.00335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    148/150      7.83G      3.302      2.013      0.717        184       2048: 100% ━━━━━━━━━━━━ 1000/1000 10.1it/s 1:39.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.3it/s 18.9s.5s\n",
      "                   all        200     127491     0.0222    0.00904      0.012    0.00305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    149/150      10.5G      3.284      1.988     0.7134        444       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:050.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.4it/s 18.6s.5s\n",
      "                   all        200     127491     0.0213    0.00871     0.0117    0.00306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    150/150      10.1G      3.321       2.02     0.7169          8       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.4it/s 1:46<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0238    0.00968     0.0129    0.00335\n",
      "\n",
      "150 epochs completed in 9.448 hours.\n",
      "Optimizer stripped from C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e\\weights\\best.pt...\n",
      "Ultralytics 8.3.230  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 13.7it/s 7.3s.1s\n",
      "                   all        200     127491     0.0162    0.00667     0.0131      0.005\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000_150e\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000022705BF8940>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,    0.064403,     0.04769,    0.030217,    0.026051,    0.024227,    0.021345,    0.016164,    0.016147,    0.016131,    0.016115,    0.016099,    0.016082,    0.016066,     0.01605,    0.016033,    0.016017,    0.016001,    0.015984,    0.015968,    0.015952,    0.015936,    0.015919,\n",
       "           0.015903,    0.015887,     0.01587,    0.015854,    0.015838,    0.015822,    0.015805,    0.015789,    0.015773,    0.015756,     0.01574,    0.015724,    0.015707,    0.015691,    0.015675,    0.015659,    0.015642,    0.015626,     0.01561,    0.015593,    0.015577,    0.015561,    0.015545,\n",
       "           0.015528,    0.015512,    0.015496,    0.015479,    0.015463,    0.015447,     0.01543,    0.015414,    0.015398,    0.015382,    0.015365,    0.015349,    0.015333,    0.015316,      0.0153,    0.015284,    0.015268,    0.015251,    0.015235,    0.015219,    0.015202,    0.015186,     0.01517,\n",
       "           0.015153,    0.015137,    0.015121,    0.015105,    0.015088,    0.015072,    0.015056,    0.015039,    0.015023,    0.015007,    0.014991,    0.014974,    0.014958,    0.014942,    0.014925,    0.014909,    0.014893,    0.014876,     0.01486,    0.014844,    0.014828,    0.014811,    0.014795,\n",
       "           0.014779,    0.014762,    0.014746,     0.01473,    0.014714,    0.014697,    0.014681,    0.014665,    0.014648,    0.014632,    0.014616,    0.014599,    0.014583,    0.014567,    0.014551,    0.014534,    0.014518,    0.014502,    0.014485,    0.014469,    0.014453,    0.014437,     0.01442,\n",
       "           0.014404,    0.014388,    0.014371,    0.014355,    0.014339,    0.014322,    0.014306,     0.01429,    0.014274,    0.014257,    0.014241,    0.014225,    0.014208,    0.014192,    0.014176,     0.01416,    0.014143,    0.014127,    0.014111,    0.014094,    0.014078,    0.014062,    0.014045,\n",
       "           0.014029,    0.014013,    0.013997,     0.01398,    0.013964,    0.013948,    0.013931,    0.013915,    0.013899,    0.013883,    0.013866,     0.01385,    0.013834,    0.013817,    0.013801,    0.013785,    0.013768,    0.013752,    0.013736,     0.01372,    0.013703,    0.013687,    0.013671,\n",
       "           0.013654,    0.013638,    0.013622,    0.013606,    0.013589,    0.013573,    0.013557,     0.01354,    0.013524,    0.013508,    0.013491,    0.013475,    0.013459,    0.013443,    0.013426,     0.01341,    0.013394,    0.013377,    0.013361,    0.013345,    0.013329,    0.013312,    0.013296,\n",
       "            0.01328,    0.013263,    0.013247,    0.013231,    0.013214,    0.013198,    0.013182,    0.013166,    0.013149,    0.013133,    0.013117,      0.0131,    0.013084,    0.013068,    0.013052,    0.013035,    0.013019,    0.013003,    0.012986,     0.01297,    0.012954,    0.012937,    0.012921,\n",
       "           0.012905,    0.012889,    0.012872,    0.012856,     0.01284,    0.012823,    0.012807,    0.012791,    0.012775,    0.012758,    0.012742,    0.012726,    0.012709,    0.012693,    0.012677,     0.01266,    0.012644,    0.012628,    0.012612,    0.012595,    0.012579,    0.012563,    0.012546,\n",
       "            0.01253,    0.012514,    0.012498,    0.012481,    0.012465,    0.012449,    0.012432,    0.012416,      0.0124,    0.012383,    0.012367,    0.012351,    0.012335,    0.012318,    0.012302,    0.012286,    0.012269,    0.012253,    0.012237,    0.012221,    0.012204,    0.012188,    0.012172,\n",
       "           0.012155,    0.012139,    0.012123,    0.012106,     0.01209,    0.012074,    0.012058,    0.012041,    0.012025,    0.012009,    0.011992,    0.011976,     0.01196,    0.011944,    0.011927,    0.011911,    0.011895,    0.011878,    0.011862,    0.011846,    0.011829,    0.011813,    0.011797,\n",
       "           0.011781,    0.011764,    0.011748,    0.011732,    0.011715,    0.011699,    0.011683,    0.011667,     0.01165,    0.011634,    0.011618,    0.011601,    0.011585,    0.011569,    0.011552,    0.011536,     0.01152,    0.011504,    0.011487,    0.011471,    0.011455,    0.011438,    0.011422,\n",
       "           0.011406,     0.01139,    0.011373,    0.011357,    0.011341,    0.011324,    0.011308,    0.011292,    0.011275,    0.011259,    0.011243,    0.011227,     0.01121,    0.011194,    0.011178,    0.011161,    0.011145,    0.011129,    0.011113,    0.011096,     0.01108,    0.011064,    0.011047,\n",
       "           0.011031,    0.011015,    0.010998,    0.010982,    0.010966,     0.01095,    0.010933,    0.010917,    0.010901,    0.010884,    0.010868,    0.010852,    0.010836,    0.010819,    0.010803,    0.010787,     0.01077,    0.010754,    0.010738,    0.010721,    0.010705,    0.010689,    0.010673,\n",
       "           0.010656,     0.01064,    0.010624,    0.010607,    0.010591,    0.010575,    0.010559,    0.010542,    0.010526,     0.01051,    0.010493,    0.010477,    0.010461,    0.010444,    0.010428,    0.010412,    0.010396,    0.010379,    0.010363,    0.010347,     0.01033,    0.010314,    0.010298,\n",
       "           0.010282,    0.010265,    0.010249,    0.010233,    0.010216,      0.0102,    0.010184,    0.010167,    0.010151,    0.010135,    0.010119,    0.010102,    0.010086,     0.01007,    0.010053,    0.010037,    0.010021,    0.010005,   0.0099882,    0.009972,   0.0099557,   0.0099394,   0.0099231,\n",
       "          0.0099068,   0.0098905,   0.0098742,   0.0098579,   0.0098416,   0.0098253,    0.009809,   0.0097927,   0.0097764,   0.0097601,   0.0097438,   0.0097275,   0.0097113,    0.009695,   0.0096787,   0.0096624,   0.0096461,   0.0096298,   0.0096135,   0.0095972,   0.0095809,   0.0095646,   0.0095483,\n",
       "           0.009532,   0.0095157,   0.0094994,   0.0094831,   0.0094668,   0.0094505,   0.0094343,    0.009418,   0.0094017,   0.0093854,   0.0093691,   0.0093528,   0.0093365,   0.0093202,   0.0093039,   0.0092876,   0.0092713,    0.009255,   0.0092387,   0.0092224,   0.0092061,   0.0091898,   0.0091735,\n",
       "          0.0091573,    0.009141,   0.0091247,   0.0091084,   0.0090921,   0.0090758,   0.0090595,   0.0090432,   0.0090269,   0.0090106,   0.0089943,    0.008978,   0.0089617,   0.0089454,   0.0089291,   0.0089128,   0.0088965,   0.0088803,    0.008864,   0.0088477,   0.0088314,   0.0088151,   0.0087988,\n",
       "          0.0087825,   0.0087662,   0.0087499,   0.0087336,   0.0087173,    0.008701,   0.0086847,   0.0086684,   0.0086521,   0.0086358,   0.0086195,   0.0086033,    0.008587,   0.0085707,   0.0085544,   0.0085381,   0.0085218,   0.0085055,   0.0084892,   0.0084729,   0.0084566,   0.0084403,    0.008424,\n",
       "          0.0084077,   0.0083914,   0.0083751,   0.0083588,   0.0083426,   0.0083263,     0.00831,   0.0082937,   0.0082774,   0.0082611,   0.0082448,   0.0082285,   0.0082122,   0.0081959,   0.0081796,   0.0081633,    0.008147,   0.0081307,   0.0081144,   0.0080981,   0.0080818,   0.0080656,   0.0080493,\n",
       "           0.008033,   0.0080167,   0.0080004,   0.0079841,   0.0079678,   0.0079515,   0.0079352,   0.0079189,   0.0079026,   0.0078863,     0.00787,   0.0078537,   0.0078374,   0.0078211,   0.0078048,   0.0077886,   0.0077723,    0.007756,   0.0077397,   0.0077234,   0.0077071,   0.0076908,   0.0076745,\n",
       "          0.0076582,   0.0076419,   0.0076256,   0.0076093,    0.007593,   0.0075767,   0.0075604,   0.0075441,   0.0075278,   0.0075116,   0.0074953,    0.007479,   0.0074627,   0.0074464,   0.0074301,   0.0074138,   0.0073975,   0.0073812,   0.0073649,   0.0073486,   0.0073323,    0.007316,   0.0072997,\n",
       "          0.0072834,   0.0072671,   0.0072509,   0.0072346,   0.0072183,    0.007202,   0.0071857,   0.0071694,   0.0071531,   0.0071368,   0.0071205,   0.0071042,   0.0070879,   0.0070716,   0.0070553,    0.007039,   0.0070227,   0.0070064,   0.0069901,   0.0069739,   0.0069576,   0.0069413,    0.006925,\n",
       "          0.0069087,   0.0068924,   0.0068761,   0.0068598,   0.0068435,   0.0068272,   0.0068109,   0.0067946,   0.0067783,    0.006762,   0.0067457,   0.0067294,   0.0067131,   0.0066969,   0.0066806,   0.0066643,    0.006648,   0.0066317,   0.0066154,   0.0065991,   0.0065828,   0.0065665,   0.0065502,\n",
       "          0.0065339,   0.0065176,   0.0065013,    0.006485,   0.0064687,   0.0064524,   0.0064361,   0.0064199,   0.0064036,   0.0063873,    0.006371,   0.0063547,   0.0063384,   0.0063221,   0.0063058,   0.0062895,   0.0062732,   0.0062569,   0.0062406,   0.0062243,    0.006208,   0.0061917,   0.0061754,\n",
       "          0.0061591,   0.0061429,   0.0061266,   0.0061103,    0.006094,   0.0060777,   0.0060614,   0.0060451,   0.0060288,   0.0060125,   0.0059962,   0.0059799,   0.0059636,   0.0059473,    0.005931,   0.0059147,   0.0058984,   0.0058822,   0.0058659,   0.0058496,   0.0058333,    0.005817,   0.0058007,\n",
       "          0.0057844,   0.0057681,   0.0057518,   0.0057355,   0.0057192,   0.0057029,   0.0056866,   0.0056703,    0.005654,   0.0056377,   0.0056214,   0.0056052,   0.0055889,   0.0055726,   0.0055563,     0.00554,   0.0055237,   0.0055074,   0.0054911,   0.0054748,   0.0054585,   0.0054422,   0.0054259,\n",
       "          0.0054096,   0.0053933,    0.005377,   0.0053607,   0.0053444,   0.0053282,   0.0053119,   0.0052956,   0.0052793,    0.005263,   0.0052467,   0.0052304,   0.0052141,   0.0051978,   0.0051815,   0.0051652,   0.0051489,   0.0051326,   0.0051163,      0.0051,   0.0050837,   0.0050674,   0.0050512,\n",
       "          0.0050349,   0.0050186,   0.0050023,    0.004986,   0.0049697,   0.0049534,   0.0049371,   0.0049208,   0.0049045,   0.0048882,   0.0048719,   0.0048556,   0.0048393,    0.004823,   0.0048067,   0.0047904,   0.0047742,   0.0047579,   0.0047416,   0.0047253,    0.004709,   0.0046927,   0.0046764,\n",
       "          0.0046601,   0.0046438,   0.0046275,   0.0046112,   0.0045949,   0.0045786,   0.0045623,    0.004546,   0.0045297,   0.0045135,   0.0044972,   0.0044809,   0.0044646,   0.0044483,    0.004432,   0.0044157,   0.0043994,   0.0043831,   0.0043668,   0.0043505,   0.0043342,   0.0043179,   0.0043016,\n",
       "          0.0042853,    0.004269,   0.0042527,   0.0042365,   0.0042202,   0.0042039,   0.0041876,   0.0041713,    0.004155,   0.0041387,   0.0041224,   0.0041061,   0.0040898,   0.0040735,   0.0040572,   0.0040409,   0.0040246,   0.0040083,    0.003992,   0.0039757,   0.0039595,   0.0039432,   0.0039269,\n",
       "          0.0039106,   0.0038943,    0.003878,   0.0038617,   0.0038454,   0.0038291,   0.0038128,   0.0037965,   0.0037802,   0.0037639,   0.0037476,   0.0037313,    0.003715,   0.0036987,   0.0036825,   0.0036662,   0.0036499,   0.0036336,   0.0036173,    0.003601,   0.0035847,   0.0035684,   0.0035521,\n",
       "          0.0035358,   0.0035195,   0.0035032,   0.0034869,   0.0034706,   0.0034543,    0.003438,   0.0034217,   0.0034055,   0.0033892,   0.0033729,   0.0033566,   0.0033403,    0.003324,   0.0033077,   0.0032914,   0.0032751,   0.0032588,   0.0032425,   0.0032262,   0.0032099,   0.0031936,   0.0031773,\n",
       "           0.003161,   0.0031448,   0.0031285,   0.0031122,   0.0030959,   0.0030796,   0.0030633,    0.003047,   0.0030307,   0.0030144,   0.0029981,   0.0029818,   0.0029655,   0.0029492,   0.0029329,   0.0029166,   0.0029003,    0.002884,   0.0028678,   0.0028515,   0.0028352,   0.0028189,   0.0028026,\n",
       "          0.0027863,     0.00277,   0.0027537,   0.0027374,   0.0027211,   0.0027048,   0.0026885,   0.0026722,   0.0026559,   0.0026396,   0.0026233,    0.002607,   0.0025908,   0.0025745,   0.0025582,   0.0025419,   0.0025256,   0.0025093,    0.002493,   0.0024767,   0.0024604,   0.0024441,   0.0024278,\n",
       "          0.0024115,   0.0023952,   0.0023789,   0.0023626,   0.0023463,     0.00233,   0.0023138,   0.0022975,   0.0022812,   0.0022649,   0.0022486,   0.0022323,    0.002216,   0.0021997,   0.0021834,   0.0021671,   0.0021508,   0.0021345,   0.0021182,   0.0021019,   0.0020856,   0.0020693,    0.002053,\n",
       "          0.0020368,   0.0020205,   0.0020042,   0.0019879,   0.0019716,   0.0019553,    0.001939,   0.0019227,   0.0019064,   0.0018901,   0.0018738,   0.0018575,   0.0018412,   0.0018249,   0.0018086,   0.0017923,   0.0017761,   0.0017598,   0.0017435,   0.0017272,   0.0017109,   0.0016946,   0.0016783,\n",
       "           0.001662,   0.0016457,   0.0016294,   0.0016131,   0.0015968,   0.0015805,   0.0015642,   0.0015479,   0.0015316,   0.0015153,   0.0014991,   0.0014828,   0.0014665,   0.0014502,   0.0014339,   0.0014176,   0.0014013,    0.001385,   0.0013687,   0.0013524,   0.0013361,   0.0013198,   0.0013035,\n",
       "          0.0012872,   0.0012709,   0.0012546,   0.0012383,   0.0012221,   0.0012058,   0.0011895,   0.0011732,   0.0011569,   0.0011406,   0.0011243,    0.001108,   0.0010917,   0.0010754,   0.0010591,   0.0010428,   0.0010265,   0.0010102,  0.00099394,  0.00097764,  0.00096135,  0.00094505,  0.00092876,\n",
       "         0.00091247,  0.00089617,  0.00087988,  0.00086358,  0.00084729,    0.000831,   0.0008147,  0.00079841,  0.00078211,  0.00076582,  0.00074953,  0.00073323,  0.00071694,  0.00070064,  0.00068435,  0.00066806,  0.00065176,  0.00063547,  0.00061917,  0.00060288,  0.00058659,  0.00057029,    0.000554,\n",
       "          0.0005377,  0.00052141,  0.00050512,  0.00048882,  0.00047253,  0.00045623,  0.00043994,  0.00042365,  0.00040735,  0.00039106,  0.00037476,  0.00035847,  0.00034217,  0.00032588,  0.00030959,  0.00029329,    0.000277,   0.0002607,  0.00024441,  0.00022812,  0.00021182,  0.00019553,  0.00017923,\n",
       "         0.00016294,  0.00014665,  0.00013035,  0.00011406,  9.7764e-05,   8.147e-05,  6.5176e-05,  4.8882e-05,  3.2588e-05,  1.6294e-05,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0094413,   0.0094413,   0.0095131,    0.009543,   0.0095782,   0.0096135,   0.0096196,   0.0096327,   0.0096354,   0.0096391,   0.0096461,   0.0096537,   0.0096411,   0.0096253,    0.009549,   0.0094983,   0.0094976,    0.009463,   0.0094556,   0.0094554,   0.0094573,     0.00936,   0.0093067,\n",
       "          0.0092151,   0.0091233,   0.0090442,   0.0089074,   0.0087352,   0.0086537,   0.0084992,   0.0084358,   0.0082519,   0.0079922,   0.0077337,   0.0072531,   0.0069428,   0.0066641,   0.0062559,   0.0059175,   0.0055802,   0.0052435,   0.0048808,   0.0046504,   0.0043542,   0.0040292,    0.003755,\n",
       "          0.0035028,   0.0031974,    0.002843,   0.0026074,   0.0023068,   0.0020962,   0.0019009,   0.0017186,   0.0016128,   0.0015063,   0.0013062,   0.0012296,   0.0011841,   0.0011022,  0.00096747,  0.00090569,  0.00079679,  0.00070341,  0.00062551,  0.00059445,  0.00051642,  0.00046959,  0.00040709,\n",
       "         0.00036019,  0.00032883,  0.00026633,   0.0002507,   0.0002194,  0.00021942,  0.00021946,  0.00020602,  0.00018813,  0.00017247,  0.00015681,  0.00012546,  0.00012546,  0.00012547,  0.00012547,  0.00012547,  0.00010979,  0.00010591,  9.6019e-05,  7.8425e-05,  7.8426e-05,  7.4665e-05,  6.2742e-05,\n",
       "         6.2742e-05,  6.2742e-05,  6.2743e-05,  4.7058e-05,  4.7059e-05,  4.7059e-05,  4.7059e-05,  3.7242e-05,  3.1373e-05,  3.1373e-05,  3.1373e-05,  3.1373e-05,  3.1373e-05,  3.1373e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,  3.1374e-05,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016169,    0.016169,    0.016796,     0.01714,    0.017424,    0.017659,    0.017815,    0.017963,      0.0181,    0.018247,    0.018421,    0.018602,    0.018767,     0.01898,    0.019141,     0.01938,    0.019757,    0.020095,     0.02045,    0.020803,    0.021194,    0.021366,    0.021617,\n",
       "           0.021784,    0.021966,      0.0222,    0.022365,    0.022494,    0.022921,    0.023243,    0.023897,    0.024414,    0.024657,    0.025283,    0.025221,    0.025924,    0.026848,    0.027484,    0.029042,    0.030139,    0.032077,    0.034245,    0.037562,    0.041315,    0.044584,    0.048513,\n",
       "           0.052444,    0.054341,    0.055449,     0.05846,    0.058651,     0.05996,    0.064032,    0.065807,    0.070238,     0.07469,    0.074278,     0.07876,     0.08623,     0.09255,    0.091427,    0.098708,    0.097665,    0.098484,    0.098621,     0.10637,     0.10538,     0.10675,     0.10615,\n",
       "            0.10415,     0.10878,    0.099465,     0.10523,     0.10836,     0.11906,     0.14464,     0.14578,     0.15087,     0.16188,     0.19059,     0.19051,     0.20775,     0.24219,     0.25655,     0.29469,     0.31823,     0.32508,     0.30406,     0.26918,     0.28251,     0.28354,     0.25066,\n",
       "            0.27014,      0.2799,     0.31833,     0.30105,     0.31761,     0.33916,     0.41042,     0.36897,     0.33931,     0.34907,     0.35883,      0.3686,     0.37836,     0.38812,     0.39788,     0.44143,     0.49433,     0.56596,     0.63984,     0.93447,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0066671,   0.0066671,   0.0066358,   0.0066122,   0.0066044,   0.0066044,   0.0065887,   0.0065809,   0.0065652,   0.0065495,   0.0065338,   0.0065181,   0.0064867,   0.0064475,   0.0063612,   0.0062906,   0.0062514,   0.0061887,   0.0061495,   0.0061181,   0.0060867,   0.0059926,   0.0059298,\n",
       "          0.0058435,   0.0057573,   0.0056788,   0.0055612,     0.00542,   0.0053337,   0.0052004,   0.0051219,   0.0049651,    0.004769,    0.004565,   0.0042356,   0.0040081,   0.0038042,   0.0035297,   0.0032944,   0.0030747,   0.0028551,   0.0026276,   0.0024786,   0.0022982,     0.00211,   0.0019531,\n",
       "          0.0018119,   0.0016472,   0.0014589,   0.0013334,   0.0011766,   0.0010667,  0.00096477,  0.00087065,  0.00081574,  0.00076084,  0.00065887,  0.00061965,  0.00059612,  0.00055438,  0.00048631,  0.00045493,  0.00040003,  0.00035297,  0.00031375,  0.00029806,  0.00025884,  0.00023531,  0.00020394,\n",
       "          0.0001804,  0.00016466,  0.00013334,   0.0001255,  0.00010981,  0.00010981,  0.00010981,  0.00010308,  9.4124e-05,  8.6281e-05,  7.8437e-05,   6.275e-05,   6.275e-05,   6.275e-05,   6.275e-05,   6.275e-05,  5.4906e-05,  5.2965e-05,  4.8017e-05,  3.9218e-05,  3.9218e-05,  3.7337e-05,  3.1375e-05,\n",
       "         3.1375e-05,  3.1375e-05,  3.1375e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  2.3531e-05,  1.8622e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,  1.5687e-05,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.005003116723462582)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([  0.0050031])\n",
       "names: {0: 'wave'}\n",
       "nt_per_class: array([127491])\n",
       "nt_per_image: array([190])\n",
       "results_dict: {'metrics/precision(B)': 0.01616922520877323, 'metrics/recall(B)': 0.006667137288122299, 'metrics/mAP50(B)': 0.013057486849364702, 'metrics/mAP50-95(B)': 0.005003116723462582, 'fitness': 0.005003116723462582}\n",
       "save_dir: WindowsPath('C:/haas/data-waves/img_labeling/runs/detect/02_waves_yolov8n-1000_150e')\n",
       "speed: {'preprocess': 1.048560999915935, 'inference': 12.795055499882437, 'loss': 0.013722500079893507, 'postprocess': 4.000321500134305}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Give a name to the run\n",
    "run_name = \"02_waves_yolov8n-1000_150e\"\n",
    "\n",
    "# Fine-tune the model\n",
    "base_model.train(\n",
    "    data=data_yaml_path,\n",
    "    device = device,\n",
    "    epochs=150,\n",
    "    imgsz=(512, 2048), #(1024,5069) - time limit exceeded, not enough comutational performance on cpu.\n",
    "    batch=1,\n",
    "    name=run_name,\n",
    "    patience=0,\n",
    "    save=True\n",
    "    #amp=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c9db6f0-c5b4-4905-aeae-b9b535252359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of runs/detect: ['.ipynb_checkpoints', '01_waves_yolov8n-500', '02_waves_yolov8n-1000', '02_waves_yolov8n-1000_150e', 'eval_base', 'eval_base_01_waves_yolov8n', 'eval_finetuned_01', 'eval_finetuned_01_waves_yolov8n', 'wave1_yolov8n', 'wave1_yolov8n2', 'wave1_yolov8n3', 'wave1_yolov8n4', 'wave1_yolov8n5', 'wave1_yolov8n6', 'wave1_yolov8n7']\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents of runs/detect:\", os.listdir(\"runs/detect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4a167a1-6586-4309-bbf9-ec7da8c90c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce MX450, 2048MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1644.0364.9 MB/s, size: 2362.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images.cache... 200 images, 10 backgrounds, 0 corrupt:\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        200     127491     0.0167    0.00689     0.0133    0.00442\n",
      "Speed: 4.7ms preprocess, 92.1ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val51\u001b[0m\n",
      "{'metrics/precision(B)': np.float64(0.0166958241423899), 'metrics/recall(B)': np.float64(0.006886760634083974), 'metrics/mAP50(B)': np.float64(0.013321742801213371), 'metrics/mAP50-95(B)': np.float64(0.004421857649280955), 'fitness': np.float64(0.005311846164474197)}\n"
     ]
    }
   ],
   "source": [
    "# rerun the missing validation step only to get metrics\n",
    "\n",
    "model_02_waves_yolov8n_1000_150e = YOLO(\"02_waves_yolov8n-1000_150e.pt\")  #last weights from 05_waves_yolov8s-5000_150e to run the validation process\n",
    "results = model_02_waves_yolov8n_1000_150e.val(data=data_yaml_path,device = device, imgsz=2048, split=\"val\")\n",
    "print(results.results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e7568-5b5d-4d31-9ae2-714e47d5cc1f",
   "metadata": {},
   "source": [
    "shutil.copy(best_model_path, destination_path)\n",
    "print(f\"✅ Saved fine-tuned model as: {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef39f9-e9b9-4035-af71-aa9527e72d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd88f8-98a6-4806-9721-a19f1c6788b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb611eec-31d0-46f2-a9d6-5e1344ed47e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96b268-478b-463c-9960-25753c3aab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664853a-1b96-4611-90fe-c4b8c5644415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9bfcc-602f-4202-8527-f81ce0dd278c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a328aaf-6acf-4cc1-847b-2459ed9f86a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
