{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef44b6ee-b30b-4809-ad0b-a47410506127",
   "metadata": {},
   "source": [
    "# Image Labeling & Model Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc9c2c-2d77-4f5d-a8cc-5a5763179e08",
   "metadata": {},
   "source": [
    "## 1. Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8d3a3d-e0d1-4fb6-b276-356ac16aaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8d6134-91fa-496c-aa04-b3704f3f33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718ef1da-295a-4c15-874f-5aeab18fb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2096e6-0dbe-486d-a04e-b5ec3b1abdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b046e1b8-2a40-4d4a-aaa9-b4c471a56953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf86f6eb-ac7b-4c10-bcb0-7b19c8a60066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47159055-f2ac-45a6-936f-ab136687d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "from ultralytics.data import utils as data_utils\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9a91df-ae56-49c9-ae32-7fea201abdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfde7ba3-d8b8-4df5-9e70-f87eb19f492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab7903-0616-4203-b290-6369b94a4471",
   "metadata": {},
   "source": [
    "## 2. Define Paths to Folders & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cbb0b4-6bbc-40d8-8f25-27b2686ae917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source images located in: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up one level to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Set path for the source folder (you can adjust as needed)\n",
    "source_folder = os.path.join(parent_dir, \"idx_images\")\n",
    "labeling_folder = os.path.join(parent_dir, \"img_labeling\")\n",
    "\n",
    "csv_out_path = os.path.join(source_folder, \"image_metadata_weather.csv\")\n",
    "csv_train = os.path.join(labeling_folder, \"train_for_training.csv\")\n",
    "csv_test = os.path.join(labeling_folder, \"test_for_training.csv\")\n",
    "csv_val = os.path.join(labeling_folder, \"val_for_training.csv\")\n",
    "\n",
    "print(f\"Source images located in: {source_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630c9e6d-73c1-4eaa-98d9-1a8a90d52bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted([f for f in os.listdir(source_folder) if f.endswith('.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f391b779-461a-473d-978b-a28d083bd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27592 images found\n"
     ]
    }
   ],
   "source": [
    "print(len(image_files), \"images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a249e63e-0851-4e09-a00a-a1d0dc84ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO model (load once)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f3473-41de-4c04-8240-1389b2d1cab9",
   "metadata": {},
   "source": [
    "## 3. Finetuning YOLO Model using stratified Train, Test, Val set and created labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d21fe4fb-2a5a-4607-a57c-4665e36e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset root where YOLO dataset will be automatically created\n",
    "dataset_root = os.path.join(parent_dir, \"waves_yolo_dataset_1000_nano\")\n",
    "os.makedirs(dataset_root, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d0c694-0396-4629-a0e2-69f570911382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lists of image names\n",
    "# -------------------------------------------------------------\n",
    "def load_image_list(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"new_image_name\" in df.columns:\n",
    "        col = \"new_image_name\"\n",
    "    elif \"image_name\" in df.columns:\n",
    "        col = \"image_name\"\n",
    "    else:\n",
    "        raise ValueError(f\"No image name column in {csv_path}\")\n",
    "    return df[col].dropna().astype(str).tolist()\n",
    "\n",
    "# Load ALL images from CSVs\n",
    "train_imgs_full = load_image_list(csv_train)\n",
    "val_imgs_full   = load_image_list(csv_val)\n",
    "test_imgs_full  = load_image_list(csv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84336701-1cb7-44a5-a0bf-d70149e3d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset: train=1000, val=200, test=200\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Subsample: 500 train, 200 val, 200 test\n",
    "# (shuffled so you don't just get the first rows)\n",
    "# -------------------------------------------------------------\n",
    "random.seed(42)  # for reproducibility\n",
    "\n",
    "train_imgs = random.sample(train_imgs_full, min(1000, len(train_imgs_full)))\n",
    "val_imgs   = random.sample(val_imgs_full,  min(200, len(val_imgs_full)))\n",
    "test_imgs  = random.sample(test_imgs_full, min(200, len(test_imgs_full)))\n",
    "\n",
    "print(f\"Using subset: train={len(train_imgs)}, val={len(val_imgs)}, test={len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3afe552c-a9a9-44ea-9d21-f46d6a17710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote split files:\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\train.txt\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\val.txt\n",
      "C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# Write YOLO split txt files with ABSOLUTE PATHS\n",
    "# -------------------------------------------------------------\n",
    "def write_split_file(img_list, out_path):\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for name in img_list:\n",
    "            full_path = os.path.abspath(os.path.join(source_folder, name))\n",
    "            f.write(full_path + \"\\n\")\n",
    "\n",
    "train_txt = os.path.join(dataset_root, \"train.txt\")\n",
    "val_txt   = os.path.join(dataset_root, \"val.txt\")\n",
    "test_txt  = os.path.join(dataset_root, \"test.txt\")\n",
    "\n",
    "write_split_file(train_imgs, train_txt)\n",
    "write_split_file(val_imgs, val_txt)\n",
    "write_split_file(test_imgs, test_txt)\n",
    "\n",
    "print(\"Wrote split files:\")\n",
    "print(train_txt)\n",
    "print(val_txt)\n",
    "print(test_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6cf582-3197-45fe-8414-29c5f197c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data.yaml at: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\01_waves.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create YOLO data.yaml\n",
    "# IMPORTANT: 'path' tells YOLO where labels live.\n",
    "# -------------------------------------------------------------\n",
    "# Normalize Windows paths before inserting into f-string\n",
    "train_txt_norm = train_txt.replace(\"\\\\\", \"/\")\n",
    "val_txt_norm   = val_txt.replace(\"\\\\\", \"/\")\n",
    "test_txt_norm  = test_txt.replace(\"\\\\\", \"/\")\n",
    "parent_dir_norm = parent_dir.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Create YOLO data.yaml\n",
    "data_yaml_path = os.path.join(dataset_root, \"01_waves.yaml\")\n",
    "\n",
    "yaml_text = f\"\"\"\n",
    "# Dataset config without copying images\n",
    "\n",
    "train: {train_txt_norm}\n",
    "val: {val_txt_norm}\n",
    "test: {test_txt_norm}\n",
    "\n",
    "names:\n",
    "  0: wave\n",
    "nc: 1\n",
    "\"\"\"\n",
    "\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(yaml_text)\n",
    "\n",
    "print(\"Created data.yaml at:\", data_yaml_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d969d-af64-4f67-aba9-911b3fbdc2df",
   "metadata": {},
   "source": [
    "##### Load model and checking if model finds labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1cb12c-e561-4c42-bb6b-675061544355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train source: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\train.txt\n",
      "Val source:   C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\val.txt\n",
      "Test source:  C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\waves_yolo_dataset_1000_nano\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model first try nano than small or medium\n",
    "base_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "info = data_utils.check_det_dataset(data_yaml_path)\n",
    "print(\"Train source:\", info[\"train\"])\n",
    "print(\"Val source:  \", info[\"val\"])\n",
    "print(\"Test source: \", info[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d2c49e1-55fe-4a15-9ac5-0d5e4c59aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing train labels: 1000\n",
      "Missing val labels:   200\n",
      "Missing test labels:  200\n",
      "Example missing label: ['img_14237.txt', 'img_15383.txt', 'img_04648.txt', 'img_16453.txt', 'img_06242.txt']\n"
     ]
    }
   ],
   "source": [
    "def count_missing_labels(txt_file, label_folder):\n",
    "    missing = []\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:\n",
    "            img_path = line.strip()\n",
    "            img_name = Path(img_path).name\n",
    "            label_name = img_name.replace(\".png\", \".txt\")\n",
    "            label_path = Path(label_folder) / label_name\n",
    "            if not label_path.exists():\n",
    "                missing.append(label_name)\n",
    "    return missing\n",
    "\n",
    "labels_folder = r\"C:/Users/A/Documents/XX_GitHub_Repo/data-waves/labels\"\n",
    "\n",
    "missing_train = count_missing_labels(info[\"train\"], labels_folder)\n",
    "missing_val   = count_missing_labels(info[\"val\"], labels_folder)\n",
    "missing_test  = count_missing_labels(info[\"test\"], labels_folder)\n",
    "\n",
    "print(\"Missing train labels:\", len(missing_train))\n",
    "print(\"Missing val labels:  \", len(missing_val))\n",
    "print(\"Missing test labels: \", len(missing_test))\n",
    "\n",
    "if missing_train:\n",
    "    print(\"Example missing label:\", missing_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c884d-0006-412c-b516-0e282cea4496",
   "metadata": {},
   "source": [
    "##### Run finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0008cb-a5dc-4d34-b965-4d395e164bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA is available. Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Device selection (GPU if available, else CPU)\n",
    "# ------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = 0  # GPU index for ultralytics (0 = first GPU)\n",
    "    print(\"✅ CUDA is available. Training on GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"⚠️ CUDA not available. Training on CPU (slower).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08344f72-3e75-432d-811c-89055e769b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.230  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\haas\\data-waves\\waves_yolo_dataset_1000_nano\\01_waves.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=(512, 2048), int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=02_waves_yolov8n-1000, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING updating to 'imgsz=2048'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2065.2152.3 MB/s, size: 2393.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\haas\\data-waves\\idx_images... 1000 images, 62 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1000/1000 458.7it/s 2.2s1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\haas\\data-waves\\idx_images.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1127.1206.5 MB/s, size: 2424.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\haas\\data-waves\\idx_images... 200 images, 10 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 200/200 188.2it/s 1.1s.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\haas\\data-waves\\idx_images.cache\n",
      "Plotting labels to C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 2048 train, 2048 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      13.6G      4.218      13.11     0.9042          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.8it/s 2:510.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 14.0s0.1s\n",
      "                   all        200     127491    0.00163   0.000769   0.000835    0.00016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      6.37G      4.138      7.302      0.851        438       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.9it/s 1:520.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 6.7it/s 14.9s.1s\n",
      "                   all        200     127491    0.00677    0.00318    0.00342   0.000759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      8.64G      4.154      5.075     0.8496         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.8it/s 2:080.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.5s0.1s\n",
      "                   all        200     127491     0.0077    0.00362    0.00428    0.00101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      6.53G      4.173      4.075      0.856        277       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.2it/s 7:440.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.5it/s 13.3s0.2s\n",
      "                   all        200     127491    0.00873    0.00384    0.00445   0.000981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      8.24G      4.094      3.714     0.8387         19       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.8it/s 3:290.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.5it/s 13.4s0.1s\n",
      "                   all        200     127491    0.00778     0.0032    0.00391   0.000862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      9.99G      4.176      3.323     0.8562        552       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.1it/s 2:030.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.7it/s 13.1s0.2s\n",
      "                   all        200     127491    0.00608    0.00254    0.00373   0.000836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      11.8G      4.167      3.242     0.8515        134       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.4it/s 11:561.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.8s0.2s\n",
      "                   all        200     127491      0.012    0.00488    0.00762    0.00185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      12.8G      4.137      3.075     0.8526         36       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:050.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.8it/s 12.9s0.2s\n",
      "                   all        200     127491     0.0194    0.00824     0.0106    0.00258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      12.6G      4.106      2.898     0.8477        199       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:030.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0171    0.00631    0.00947    0.00225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      8.57G      4.125      2.895     0.8461        317       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:100.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0115    0.00467    0.00653    0.00165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      12.2G      4.122      2.875     0.8493        259       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:130.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0106    0.00424    0.00584    0.00144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      5.29G      4.094      2.723     0.8443        193       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.2it/s 2:020.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491    0.00797    0.00313    0.00896      0.002\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      9.55G        4.1      2.751     0.8469          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.6it/s 6:280.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491      0.013     0.0055    0.00739      0.002\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      5.69G      4.082      2.684     0.8403        337       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.0it/s 2:060.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0128     0.0055    0.00774    0.00199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      8.24G      4.151      2.767     0.8553        464       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.2it/s 5:120.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0141    0.00576    0.00954    0.00244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      9.21G      4.099      2.697     0.8444        135       2048: 100% ━━━━━━━━━━━━ 1000/1000 4.8it/s 3:26<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491    0.00797    0.00324    0.00467    0.00132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50        12G      4.079      2.718     0.8412        618       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.8it/s 9:021.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0154    0.00636    0.00837    0.00222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      8.12G      4.001       2.67      0.828         72       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.4it/s 1:590.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0187    0.00758     0.0118    0.00313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      12.8G      4.071      2.666     0.8476       1055       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.9it/s 2:250.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0175    0.00706    0.00956    0.00238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      8.37G      3.991       2.61     0.8379        184       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.1it/s 7:570.3s4\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0251     0.0104     0.0139    0.00331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      7.22G      4.062       2.72     0.8404        564       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.1it/s 7:460.3s1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 1.0it/s 1:39.1ss\n",
      "                   all        200     127491      0.013    0.00499     0.0076     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      7.66G      4.046      2.641     0.8404         94       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.9it/s 4:140.3s7\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.6it/s 13.2s0.1s\n",
      "                   all        200     127491     0.0131    0.00562    0.00711    0.00185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      8.32G      4.013      2.593     0.8349         46       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.1it/s 7:530.7s6\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.4it/s 13.5s0.2s\n",
      "                   all        200     127491     0.0142    0.00582    0.00852    0.00252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      13.9G      4.021      2.528     0.8396        411       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.1it/s 14:581.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.0it/s 14.3s0.2s\n",
      "                   all        200     127491     0.0136    0.00566    0.00767     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50        10G      4.014      2.526     0.8364        216       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.1it/s 2:220.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.2it/s 13.9s0.1s\n",
      "                   all        200     127491     0.0173    0.00723      0.012    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      7.21G      4.053      2.609     0.8475        188       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.1it/s 3:170.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.5it/s 13.3s0.2s\n",
      "                   all        200     127491      0.013    0.00519    0.00894    0.00236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      12.7G      3.957      2.514     0.8322        258       2048: 100% ━━━━━━━━━━━━ 1000/1000 3.6it/s 4:380.3s1\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.7it/s 13.0s0.1s\n",
      "                   all        200     127491     0.0255     0.0107     0.0147    0.00362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      11.2G      4.021      2.576     0.8406         95       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.5it/s 2:130.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.6s0.1s\n",
      "                   all        200     127491     0.0152    0.00638     0.0101    0.00243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50       6.9G      4.042      2.537     0.8501        113       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.7it/s 2:550.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.7s0.2s\n",
      "                   all        200     127491     0.0149    0.00617    0.00911    0.00207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      12.2G      4.074      2.601     0.8503        486       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.1s/it 17:401.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0125    0.00527    0.00788    0.00212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      7.25G      4.019      2.579     0.8425        946       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:110.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.1s\n",
      "                   all        200     127491      0.018    0.00742     0.0102    0.00262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      12.8G      4.046      2.535     0.8503        564       2048: 100% ━━━━━━━━━━━━ 1000/1000 1.4it/s 11:411.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0161    0.00654     0.0091    0.00229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      9.11G       4.04      2.527     0.8498        394       2048: 100% ━━━━━━━━━━━━ 1000/1000 5.6it/s 2:591.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0137    0.00565    0.00808    0.00238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      10.8G      3.981       2.46     0.8333        220       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:120.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0134    0.00544    0.00831    0.00263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      12.8G      3.972      2.543     0.8355        246       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.0it/s 2:471.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0207    0.00849     0.0116      0.003\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      13.5G      3.992      2.497     0.8394         96       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.1it/s 2:040.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0175    0.00719    0.00971    0.00252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      6.58G       3.97      2.504     0.8303        537       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.2it/s 1:490.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0209    0.00851     0.0114    0.00289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      12.6G      3.958      2.483     0.8297        191       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.4it/s 2:150.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 7.9it/s 12.6s0.2s\n",
      "                   all        200     127491     0.0176    0.00715       0.01    0.00254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      10.9G       3.95      2.432     0.8302        292       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.6it/s 2:310.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.1s\n",
      "                   all        200     127491     0.0145    0.00594     0.0097    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      7.07G      4.001      2.471     0.8377         22       2048: 100% ━━━━━━━━━━━━ 1000/1000 6.5it/s 2:340.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0136    0.00566    0.00818    0.00224\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      5.61G      3.432      2.281     0.7235        210       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.1it/s 1:500.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491     0.0126    0.00523    0.00737    0.00188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      8.56G      3.442      2.237     0.7345         21       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.7it/s 2:090.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.4s0.2s\n",
      "                   all        200     127491     0.0143    0.00584    0.00914    0.00238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      12.3G      3.438      2.205     0.7339        305       2048: 100% ━━━━━━━━━━━━ 1000/1000 8.9it/s 1:53<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 5.3it/s 18.8s.5s\n",
      "                   all        200     127491     0.0179    0.00737     0.0106    0.00317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50        12G      3.467      2.199     0.7429          0       2048: 100% ━━━━━━━━━━━━ 1000/1000 7.6it/s 2:110.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.0it/s 12.5s0.2s\n",
      "                   all        200     127491      0.016    0.00656    0.00964    0.00303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      7.86G      3.482       2.22     0.7404        137       2048: 100% ━━━━━━━━━━━━ 1000/1000 10.1it/s 1:390.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0111     0.0046    0.00678    0.00201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      9.02G      3.421      2.188     0.7344        425       2048: 100% ━━━━━━━━━━━━ 1000/1000 2.5it/s 6:450.6s4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0141     0.0058    0.00829    0.00243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      9.01G      3.456      2.182     0.7478          3       2048: 100% ━━━━━━━━━━━━ 1000/1000 9.9it/s 1:41<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 8.1it/s 12.3s0.2s\n",
      "                   all        200     127491     0.0157    0.00646     0.0103    0.00316\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 27, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "47 epochs completed in 3.553 hours.\n",
      "Optimizer stripped from C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating C:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000\\weights\\best.pt...\n",
      "Ultralytics 8.3.230  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 100/100 13.6it/s 7.3s.1s\n",
      "                   all        200     127491     0.0255     0.0107     0.0147    0.00362\n",
      "Speed: 1.0ms preprocess, 13.5ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\haas\\data-waves\\img_labeling\\runs\\detect\\02_waves_yolov8n-1000\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002110BBEDA00>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.36364,     0.11111,    0.092613,    0.078677,    0.065137,     0.05943,    0.050558,    0.046696,    0.041725,     0.03791,    0.033868,    0.025483,    0.025458,    0.025432,    0.025406,     0.02538,    0.025354,    0.025329,    0.025303,    0.025277,    0.025251,    0.025225,      0.0252,\n",
       "           0.025174,    0.025148,    0.025122,    0.025096,    0.025071,    0.025045,    0.025019,    0.024993,    0.024967,    0.024942,    0.024916,     0.02489,    0.024864,    0.024838,    0.024813,    0.024787,    0.024761,    0.024735,     0.02471,    0.024684,    0.024658,    0.024632,    0.024606,\n",
       "           0.024581,    0.024555,    0.024529,    0.024503,    0.024477,    0.024452,    0.024426,      0.0244,    0.024374,    0.024348,    0.024323,    0.024297,    0.024271,    0.024245,    0.024219,    0.024194,    0.024168,    0.024142,    0.024116,     0.02409,    0.024065,    0.024039,    0.024013,\n",
       "           0.023987,    0.023962,    0.023936,     0.02391,    0.023884,    0.023858,    0.023833,    0.023807,    0.023781,    0.023755,    0.023729,    0.023704,    0.023678,    0.023652,    0.023626,      0.0236,    0.023575,    0.023549,    0.023523,    0.023497,    0.023471,    0.023446,     0.02342,\n",
       "           0.023394,    0.023368,    0.023343,    0.023317,    0.023291,    0.023265,    0.023239,    0.023214,    0.023188,    0.023162,    0.023136,     0.02311,    0.023085,    0.023059,    0.023033,    0.023007,    0.022981,    0.022956,     0.02293,    0.022904,    0.022878,    0.022852,    0.022827,\n",
       "           0.022801,    0.022775,    0.022749,    0.022723,    0.022698,    0.022672,    0.022646,     0.02262,    0.022595,    0.022569,    0.022543,    0.022517,    0.022491,    0.022466,     0.02244,    0.022414,    0.022388,    0.022362,    0.022337,    0.022311,    0.022285,    0.022259,    0.022233,\n",
       "           0.022208,    0.022182,    0.022156,     0.02213,    0.022104,    0.022079,    0.022053,    0.022027,    0.022001,    0.021975,     0.02195,    0.021924,    0.021898,    0.021872,    0.021847,    0.021821,    0.021795,    0.021769,    0.021743,    0.021718,    0.021692,    0.021666,     0.02164,\n",
       "           0.021614,    0.021589,    0.021563,    0.021537,    0.021511,    0.021485,     0.02146,    0.021434,    0.021408,    0.021382,    0.021356,    0.021331,    0.021305,    0.021279,    0.021253,    0.021227,    0.021202,    0.021176,     0.02115,    0.021124,    0.021099,    0.021073,    0.021047,\n",
       "           0.021021,    0.020995,     0.02097,    0.020944,    0.020918,    0.020892,    0.020866,    0.020841,    0.020815,    0.020789,    0.020763,    0.020737,    0.020712,    0.020686,     0.02066,    0.020634,    0.020608,    0.020583,    0.020557,    0.020531,    0.020505,    0.020479,    0.020454,\n",
       "           0.020428,    0.020402,    0.020376,    0.020351,    0.020325,    0.020299,    0.020273,    0.020247,    0.020222,    0.020196,     0.02017,    0.020144,    0.020118,    0.020093,    0.020067,    0.020041,    0.020015,    0.019989,    0.019964,    0.019938,    0.019912,    0.019886,     0.01986,\n",
       "           0.019835,    0.019809,    0.019783,    0.019757,    0.019732,    0.019706,     0.01968,    0.019654,    0.019628,    0.019603,    0.019577,    0.019551,    0.019525,    0.019499,    0.019474,    0.019448,    0.019422,    0.019396,     0.01937,    0.019345,    0.019319,    0.019293,    0.019267,\n",
       "           0.019241,    0.019216,     0.01919,    0.019164,    0.019138,    0.019112,    0.019087,    0.019061,    0.019035,    0.019009,    0.018984,    0.018958,    0.018932,    0.018906,     0.01888,    0.018855,    0.018829,    0.018803,    0.018777,    0.018751,    0.018726,      0.0187,    0.018674,\n",
       "           0.018648,    0.018622,    0.018597,    0.018571,    0.018545,    0.018519,    0.018493,    0.018468,    0.018442,    0.018416,     0.01839,    0.018364,    0.018339,    0.018313,    0.018287,    0.018261,    0.018236,     0.01821,    0.018184,    0.018158,    0.018132,    0.018107,    0.018081,\n",
       "           0.018055,    0.018029,    0.018003,    0.017978,    0.017952,    0.017926,      0.0179,    0.017874,    0.017849,    0.017823,    0.017797,    0.017771,    0.017745,     0.01772,    0.017694,    0.017668,    0.017642,    0.017616,    0.017591,    0.017565,    0.017539,    0.017513,    0.017488,\n",
       "           0.017462,    0.017436,     0.01741,    0.017384,    0.017359,    0.017333,    0.017307,    0.017281,    0.017255,     0.01723,    0.017204,    0.017178,    0.017152,    0.017126,    0.017101,    0.017075,    0.017049,    0.017023,    0.016997,    0.016972,    0.016946,     0.01692,    0.016894,\n",
       "           0.016869,    0.016843,    0.016817,    0.016791,    0.016765,     0.01674,    0.016714,    0.016688,    0.016662,    0.016636,    0.016611,    0.016585,    0.016559,    0.016533,    0.016507,    0.016482,    0.016456,     0.01643,    0.016404,    0.016378,    0.016353,    0.016327,    0.016301,\n",
       "           0.016275,    0.016249,    0.016224,    0.016198,    0.016172,    0.016146,    0.016121,    0.016095,    0.016069,    0.016043,    0.016017,    0.015992,    0.015966,     0.01594,    0.015914,    0.015888,    0.015863,    0.015837,    0.015811,    0.015785,    0.015759,    0.015734,    0.015708,\n",
       "           0.015682,    0.015656,     0.01563,    0.015605,    0.015579,    0.015553,    0.015527,    0.015501,    0.015476,     0.01545,    0.015424,    0.015398,    0.015373,    0.015347,    0.015321,    0.015295,    0.015269,    0.015244,    0.015218,    0.015192,    0.015166,     0.01514,    0.015115,\n",
       "           0.015089,    0.015063,    0.015037,    0.015011,    0.014986,     0.01496,    0.014934,    0.014908,    0.014882,    0.014857,    0.014831,    0.014805,    0.014779,    0.014753,    0.014728,    0.014702,    0.014676,     0.01465,    0.014625,    0.014599,    0.014573,    0.014547,    0.014521,\n",
       "           0.014496,     0.01447,    0.014444,    0.014418,    0.014392,    0.014367,    0.014341,    0.014315,    0.014289,    0.014263,    0.014238,    0.014212,    0.014186,     0.01416,    0.014134,    0.014109,    0.014083,    0.014057,    0.014031,    0.014006,     0.01398,    0.013954,    0.013928,\n",
       "           0.013902,    0.013877,    0.013851,    0.013825,    0.013799,    0.013773,    0.013748,    0.013722,    0.013696,     0.01367,    0.013644,    0.013619,    0.013593,    0.013567,    0.013541,    0.013515,     0.01349,    0.013464,    0.013438,    0.013412,    0.013386,    0.013361,    0.013335,\n",
       "           0.013309,    0.013283,    0.013258,    0.013232,    0.013206,     0.01318,    0.013154,    0.013129,    0.013103,    0.013077,    0.013051,    0.013025,       0.013,    0.012974,    0.012948,    0.012922,    0.012896,    0.012871,    0.012845,    0.012819,    0.012793,    0.012767,    0.012742,\n",
       "           0.012716,     0.01269,    0.012664,    0.012638,    0.012613,    0.012587,    0.012561,    0.012535,     0.01251,    0.012484,    0.012458,    0.012432,    0.012406,    0.012381,    0.012355,    0.012329,    0.012303,    0.012277,    0.012252,    0.012226,      0.0122,    0.012174,    0.012148,\n",
       "           0.012123,    0.012097,    0.012071,    0.012045,    0.012019,    0.011994,    0.011968,    0.011942,    0.011916,     0.01189,    0.011865,    0.011839,    0.011813,    0.011787,    0.011762,    0.011736,     0.01171,    0.011684,    0.011658,    0.011633,    0.011607,    0.011581,    0.011555,\n",
       "           0.011529,    0.011504,    0.011478,    0.011452,    0.011426,      0.0114,    0.011375,    0.011349,    0.011323,    0.011297,    0.011271,    0.011246,     0.01122,    0.011194,    0.011168,    0.011142,    0.011117,    0.011091,    0.011065,    0.011039,    0.011014,    0.010988,    0.010962,\n",
       "           0.010936,     0.01091,    0.010885,    0.010859,    0.010833,    0.010807,    0.010781,    0.010756,     0.01073,    0.010704,    0.010678,    0.010652,    0.010627,    0.010601,    0.010575,    0.010549,    0.010523,    0.010498,    0.010472,    0.010446,     0.01042,    0.010395,    0.010369,\n",
       "           0.010343,    0.010317,    0.010291,    0.010266,     0.01024,    0.010214,    0.010188,    0.010162,    0.010137,    0.010111,    0.010085,    0.010059,    0.010033,    0.010008,   0.0099818,    0.009956,   0.0099302,   0.0099044,   0.0098786,   0.0098529,   0.0098271,   0.0098013,   0.0097755,\n",
       "          0.0097497,   0.0097239,   0.0096981,   0.0096723,   0.0096465,   0.0096207,   0.0095949,   0.0095691,   0.0095433,   0.0095176,   0.0094918,    0.009466,   0.0094402,   0.0094144,   0.0093886,   0.0093628,    0.009337,   0.0093112,   0.0092854,   0.0092596,   0.0092338,    0.009208,   0.0091822,\n",
       "          0.0091565,   0.0091307,   0.0091049,   0.0090791,   0.0090533,   0.0090275,   0.0090017,   0.0089759,   0.0089501,   0.0089243,   0.0088985,   0.0088727,   0.0088469,   0.0088211,   0.0087954,   0.0087696,   0.0087438,    0.008718,   0.0086922,   0.0086664,   0.0086406,   0.0086148,    0.008589,\n",
       "          0.0085632,   0.0085374,   0.0085116,   0.0084858,     0.00846,   0.0084343,   0.0084085,   0.0083827,   0.0083569,   0.0083311,   0.0083053,   0.0082795,   0.0082537,   0.0082279,   0.0082021,   0.0081763,   0.0081505,   0.0081247,   0.0080989,   0.0080732,   0.0080474,   0.0080216,   0.0079958,\n",
       "            0.00797,   0.0079442,   0.0079184,   0.0078926,   0.0078668,    0.007841,   0.0078152,   0.0077894,   0.0077636,   0.0077378,   0.0077121,   0.0076863,   0.0076605,   0.0076347,   0.0076089,   0.0075831,   0.0075573,   0.0075315,   0.0075057,   0.0074799,   0.0074541,   0.0074283,   0.0074025,\n",
       "          0.0073767,    0.007351,   0.0073252,   0.0072994,   0.0072736,   0.0072478,    0.007222,   0.0071962,   0.0071704,   0.0071446,   0.0071188,    0.007093,   0.0070672,   0.0070414,   0.0070156,   0.0069899,   0.0069641,   0.0069383,   0.0069125,   0.0068867,   0.0068609,   0.0068351,   0.0068093,\n",
       "          0.0067835,   0.0067577,   0.0067319,   0.0067061,   0.0066803,   0.0066545,   0.0066288,    0.006603,   0.0065772,   0.0065514,   0.0065256,   0.0064998,    0.006474,   0.0064482,   0.0064224,   0.0063966,   0.0063708,    0.006345,   0.0063192,   0.0062934,   0.0062677,   0.0062419,   0.0062161,\n",
       "          0.0061903,   0.0061645,   0.0061387,   0.0061129,   0.0060871,   0.0060613,   0.0060355,   0.0060097,   0.0059839,   0.0059581,   0.0059323,   0.0059066,   0.0058808,    0.005855,   0.0058292,   0.0058034,   0.0057776,   0.0057518,    0.005726,   0.0057002,   0.0056744,   0.0056486,   0.0056228,\n",
       "           0.005597,   0.0055712,   0.0055455,   0.0055197,   0.0054939,   0.0054681,   0.0054423,   0.0054165,   0.0053907,   0.0053649,   0.0053391,   0.0053133,   0.0052875,   0.0052617,   0.0052359,   0.0052101,   0.0051844,   0.0051586,   0.0051328,    0.005107,   0.0050812,   0.0050554,   0.0050296,\n",
       "          0.0050038,    0.004978,   0.0049522,   0.0049264,   0.0049006,   0.0048748,   0.0048491,   0.0048233,   0.0047975,   0.0047717,   0.0047459,   0.0047201,   0.0046943,   0.0046685,   0.0046427,   0.0046169,   0.0045911,   0.0045653,   0.0045395,   0.0045137,    0.004488,   0.0044622,   0.0044364,\n",
       "          0.0044106,   0.0043848,    0.004359,   0.0043332,   0.0043074,   0.0042816,   0.0042558,     0.00423,   0.0042042,   0.0041784,   0.0041526,   0.0041269,   0.0041011,   0.0040753,   0.0040495,   0.0040237,   0.0039979,   0.0039721,   0.0039463,   0.0039205,   0.0038947,   0.0038689,   0.0038431,\n",
       "          0.0038173,   0.0037915,   0.0037658,     0.00374,   0.0037142,   0.0036884,   0.0036626,   0.0036368,    0.003611,   0.0035852,   0.0035594,   0.0035336,   0.0035078,    0.003482,   0.0034562,   0.0034304,   0.0034047,   0.0033789,   0.0033531,   0.0033273,   0.0033015,   0.0032757,   0.0032499,\n",
       "          0.0032241,   0.0031983,   0.0031725,   0.0031467,   0.0031209,   0.0030951,   0.0030693,   0.0030436,   0.0030178,    0.002992,   0.0029662,   0.0029404,   0.0029146,   0.0028888,    0.002863,   0.0028372,   0.0028114,   0.0027856,   0.0027598,    0.002734,   0.0027082,   0.0026825,   0.0026567,\n",
       "          0.0026309,   0.0026051,   0.0025793,   0.0025535,   0.0025277,   0.0025019,   0.0024761,   0.0024503,   0.0024245,   0.0023987,   0.0023729,   0.0023471,   0.0023214,   0.0022956,   0.0022698,    0.002244,   0.0022182,   0.0021924,   0.0021666,   0.0021408,    0.002115,   0.0020892,   0.0020634,\n",
       "          0.0020376,   0.0020118,    0.001986,   0.0019603,   0.0019345,   0.0019087,   0.0018829,   0.0018571,   0.0018313,   0.0018055,   0.0017797,   0.0017539,   0.0017281,   0.0017023,   0.0016765,   0.0016507,   0.0016249,   0.0015992,   0.0015734,   0.0015476,   0.0015218,    0.001496,   0.0014702,\n",
       "          0.0014444,   0.0014186,   0.0013928,    0.001367,   0.0013412,   0.0013154,   0.0012896,   0.0012638,   0.0012381,   0.0012123,   0.0011865,   0.0011607,   0.0011349,   0.0011091,   0.0010833,   0.0010575,   0.0010317,   0.0010059,  0.00098013,  0.00095433,  0.00092854,  0.00090275,  0.00087696,\n",
       "         0.00085116,  0.00082537,  0.00079958,  0.00077378,  0.00074799,   0.0007222,  0.00069641,  0.00067061,  0.00064482,  0.00061903,  0.00059323,  0.00056744,  0.00054165,  0.00051586,  0.00049006,  0.00046427,  0.00043848,  0.00041269,  0.00038689,   0.0003611,  0.00033531,  0.00030951,  0.00028372,\n",
       "         0.00025793,  0.00023214,  0.00020634,  0.00018055,  0.00015476,  0.00012896,  0.00010317,  7.7378e-05,  5.1586e-05,  2.5793e-05,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.01508,     0.01508,    0.015264,    0.015404,    0.015461,     0.01553,    0.015571,    0.015576,    0.015594,      0.0156,    0.015572,    0.015551,     0.01549,    0.015431,    0.015438,    0.015387,    0.015374,    0.015206,    0.015134,    0.014972,    0.014889,    0.014821,    0.014719,\n",
       "           0.014592,    0.014385,    0.014218,    0.014098,    0.013972,    0.013761,    0.013639,    0.013391,    0.013191,    0.012981,    0.012772,    0.012572,     0.01225,    0.011942,    0.011678,    0.011132,    0.010736,    0.010292,   0.0098912,   0.0094924,   0.0091396,   0.0084179,   0.0079207,\n",
       "          0.0074844,   0.0071069,   0.0067849,   0.0064136,   0.0060434,   0.0057727,   0.0055021,   0.0052723,   0.0050693,    0.004851,   0.0045536,   0.0043919,    0.004093,   0.0039305,    0.003797,   0.0033718,   0.0032214,   0.0029633,   0.0028888,   0.0027214,    0.002662,   0.0024786,   0.0022641,\n",
       "          0.0021392,   0.0020964,   0.0020204,   0.0019134,   0.0018207,   0.0016819,   0.0015426,   0.0015431,    0.001466,   0.0014043,   0.0013111,    0.001218,   0.0011402,   0.0010624,   0.0010159,  0.00095354,  0.00090688,  0.00086014,  0.00084463,   0.0007979,   0.0007824,  0.00075126,  0.00067313,\n",
       "         0.00061063,   0.0006107,  0.00057947,  0.00056388,  0.00046997,  0.00043869,   0.0004074,  0.00040742,  0.00036043,  0.00034478,  0.00031345,  0.00031024,  0.00026648,  0.00025081,  0.00025082,  0.00021948,  0.00020382,  0.00017247,  0.00014112,  0.00014113,  0.00012545,  0.00012545,  0.00012546,\n",
       "         0.00012546,  0.00012546,  0.00012546,  0.00012546,  9.7129e-05,  9.4101e-05,  9.4102e-05,  9.4103e-05,  9.4104e-05,  9.4107e-05,  9.4108e-05,  9.4108e-05,  9.4108e-05,  9.4108e-05,  9.4109e-05,  9.4109e-05,   9.411e-05,   9.411e-05,   9.411e-05,  6.8875e-05,  6.2741e-05,  6.2742e-05,  6.2742e-05,\n",
       "         6.2743e-05,  6.2744e-05,  6.2744e-05,  3.1373e-05,  2.1662e-05,  1.5687e-05,  1.5687e-05,  1.5573e-05,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.025491,    0.025491,    0.026675,    0.027602,     0.02824,    0.028884,     0.02947,    0.029939,    0.030466,    0.030918,    0.031326,    0.031806,    0.032293,    0.032732,     0.03339,    0.033971,     0.03459,    0.034931,    0.035507,    0.035884,    0.036416,    0.036927,    0.037416,\n",
       "           0.037896,    0.038157,    0.038595,    0.039321,    0.040017,    0.040452,    0.041176,    0.041675,    0.042567,    0.043395,     0.04439,    0.045453,    0.046267,    0.047382,    0.048631,    0.049268,    0.050384,    0.052065,    0.054069,    0.056123,    0.059591,    0.060113,    0.062611,\n",
       "           0.065521,    0.068038,    0.071656,    0.075389,    0.076935,    0.078662,    0.081431,    0.083821,    0.085633,     0.08795,    0.087805,    0.089602,    0.089767,    0.092296,    0.094595,    0.090887,    0.092184,    0.091738,    0.094799,    0.094866,    0.099184,    0.099191,    0.098786,\n",
       "           0.099753,     0.10361,     0.10889,     0.10995,     0.11344,     0.11507,     0.11408,     0.12027,     0.12524,     0.13044,     0.13074,     0.13265,     0.13141,     0.13177,     0.13549,     0.13458,      0.1381,     0.13934,      0.1438,      0.1481,     0.15573,     0.16272,     0.15872,\n",
       "              0.158,     0.16901,     0.17393,     0.18387,     0.17069,     0.17299,     0.17454,     0.18564,     0.17273,     0.17159,     0.16733,     0.18027,      0.1699,     0.17145,     0.18061,     0.17103,     0.17509,     0.16528,     0.14756,     0.16467,     0.15464,     0.16285,      0.1793,\n",
       "            0.18987,     0.19867,     0.20471,     0.21814,     0.18102,     0.19087,      0.1956,     0.20675,      0.2201,     0.25439,     0.26428,     0.27122,     0.27607,     0.28033,     0.28458,     0.29801,     0.30439,     0.30937,     0.31435,     0.25191,     0.24391,     0.26696,     0.27737,\n",
       "            0.29466,     0.33795,     0.35866,     0.24285,     0.18367,     0.14718,     0.15694,     0.16546,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.010707,    0.010707,    0.010691,    0.010683,    0.010644,     0.01062,    0.010581,    0.010526,    0.010479,    0.010432,    0.010362,    0.010291,    0.010189,    0.010095,     0.01004,   0.0099458,   0.0098831,   0.0097183,   0.0096164,   0.0094595,   0.0093575,   0.0092712,   0.0091614,\n",
       "          0.0090359,   0.0088634,   0.0087143,   0.0085888,   0.0084633,   0.0082908,   0.0081731,    0.007977,   0.0078045,   0.0076319,   0.0074594,   0.0072946,   0.0070593,   0.0068319,   0.0066358,    0.006275,   0.0060083,   0.0057102,   0.0054435,   0.0051847,   0.0049494,   0.0045258,   0.0042277,\n",
       "          0.0039689,   0.0037493,    0.003561,   0.0033493,   0.0031452,   0.0029963,   0.0028473,   0.0027218,   0.0026119,   0.0024943,   0.0023374,   0.0022511,   0.0020943,    0.002008,   0.0019374,   0.0017178,   0.0016393,    0.001506,   0.0014668,   0.0013805,   0.0013491,    0.001255,   0.0011452,\n",
       "          0.0010812,   0.0010589,   0.0010197,  0.00096511,  0.00091771,  0.00084712,  0.00077653,  0.00077653,  0.00073731,  0.00070593,  0.00065887,  0.00061181,  0.00057259,  0.00053337,  0.00050984,  0.00047847,  0.00045493,   0.0004314,  0.00042356,  0.00040003,  0.00039218,   0.0003765,  0.00033728,\n",
       "          0.0003059,   0.0003059,  0.00029022,  0.00028237,  0.00023531,  0.00021962,  0.00020394,  0.00020394,   0.0001804,  0.00017256,  0.00015687,  0.00015525,  0.00013334,   0.0001255,   0.0001255,  0.00010981,  0.00010197,  8.6281e-05,  7.0593e-05,  7.0593e-05,   6.275e-05,   6.275e-05,   6.275e-05,\n",
       "          6.275e-05,   6.275e-05,   6.275e-05,   6.275e-05,  4.8577e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  4.7062e-05,  3.4442e-05,  3.1375e-05,  3.1375e-05,  3.1375e-05,\n",
       "         3.1375e-05,  3.1375e-05,  3.1375e-05,  1.5687e-05,  1.0832e-05,  7.8437e-06,  7.8437e-06,  7.7868e-06,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.0036150682748943785)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([  0.0036151])\n",
       "names: {0: 'wave'}\n",
       "nt_per_class: array([127491])\n",
       "nt_per_image: array([190])\n",
       "results_dict: {'metrics/precision(B)': 0.025491148128781654, 'metrics/recall(B)': 0.010706638115631691, 'metrics/mAP50(B)': 0.014656443923376356, 'metrics/mAP50-95(B)': 0.0036150682748943785, 'fitness': 0.0036150682748943785}\n",
       "save_dir: WindowsPath('C:/haas/data-waves/img_labeling/runs/detect/02_waves_yolov8n-1000')\n",
       "speed: {'preprocess': 1.0279769999488053, 'inference': 13.518944499965073, 'loss': 0.013288999998621875, 'postprocess': 3.9014940000106435}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Give a name to the run\n",
    "run_name = \"02_waves_yolov8n-1000\"\n",
    "\n",
    "# Fine-tune the model\n",
    "base_model.train(\n",
    "    data=data_yaml_path,\n",
    "    device = device,\n",
    "    epochs=50,\n",
    "    imgsz=(512, 2048), #(1024,5069) - time limit exceeded, not enough comutational performance on cpu.\n",
    "    batch=1,\n",
    "    name=run_name,\n",
    "    patience=20,\n",
    "    save=True\n",
    "    #amp=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c9db6f0-c5b4-4905-aeae-b9b535252359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of runs/detect: ['.ipynb_checkpoints', '01_waves_yolov8n-500', '02_waves_yolov8n-1000', '02_waves_yolov8n-1000_150e', 'eval_base', 'eval_base_01_waves_yolov8n', 'eval_finetuned_01', 'eval_finetuned_01_waves_yolov8n', 'wave1_yolov8n', 'wave1_yolov8n2', 'wave1_yolov8n3', 'wave1_yolov8n4', 'wave1_yolov8n5', 'wave1_yolov8n6', 'wave1_yolov8n7']\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents of runs/detect:\", os.listdir(\"runs/detect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4510c5e3-a8ff-4fb2-bf11-120ab21b89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168  Python-3.9.21 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce MX450, 2048MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 861.7620.0 MB/s, size: 2362.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images... 200 images, 10 backgrounds, 0 corrupt: 100%|\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\A\\Documents\\XX_GitHub_Repo\\data-waves\\idx_images.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        200     127491     0.0259     0.0109     0.0144    0.00365\n",
      "Speed: 5.9ms preprocess, 95.4ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val50\u001b[0m\n",
      "{'metrics/precision(B)': np.float64(0.025930143558534173), 'metrics/recall(B)': np.float64(0.010894886697884557), 'metrics/mAP50(B)': np.float64(0.01443276065909932), 'metrics/mAP50-95(B)': np.float64(0.0036509929859407835), 'fitness': np.float64(0.004729169753256638)}\n"
     ]
    }
   ],
   "source": [
    "# rerun the missing validation step only to get metrics\n",
    "\n",
    "model_02_waves_yolov8n_1000_50e = YOLO(\"02_waves_yolov8n-1000_50e.pt\")  #last weights from 05_waves_yolov8s-5000_150e to run the validation process\n",
    "results = model_02_waves_yolov8n_1000_50e.val(data=data_yaml_path,device = device, imgsz=2048, split=\"val\")\n",
    "print(results.results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef39f9-e9b9-4035-af71-aa9527e72d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427677fa-56dc-4f72-9375-968ab3230f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd88f8-98a6-4806-9721-a19f1c6788b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96b268-478b-463c-9960-25753c3aab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664853a-1b96-4611-90fe-c4b8c5644415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9bfcc-602f-4202-8527-f81ce0dd278c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a328aaf-6acf-4cc1-847b-2459ed9f86a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
